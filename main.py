import os
import time
import json
import datetime
import requests
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
# --- C·∫¢I TI·∫æN 1: Import PyTorch v√† ki·ªÉm tra thi·∫øt b·ªã n√¢ng cao ---
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import torch.optim as optim
import torch.multiprocessing as mp # C√≥ th·ªÉ d√πng cho song song h√≥a d·ªØ li·ªáu n·∫øu c·∫ßn m·ªü r·ªông
# --- H·∫æT C·∫¢I TI·∫æN 1 ---
import ta
import warnings
import google.generativeai as genai
from dotenv import load_dotenv
from vnstock import *
import traceback
from vnstock.explorer.vci import Quote, Finance
import matplotlib.dates as mdates
import mplfinance as mpf
warnings.filterwarnings("ignore")
# ======================
# C·∫§U H√åNH V√Ä TH∆Ø VI·ªÜN
# ======================
# --- BI·∫æN GLOBAL ---
GLOBAL_EPOCHS = 50 # ƒê√£ s·ª≠a th√†nh 50 ƒë·ªÉ m√¥ h√¨nh c√≥ th·ªÉ ch·∫°y
GLOBAL_BATCH_SIZE = 128 # TƒÉng batch size ƒë·ªÉ t·∫≠n d·ª•ng t·ªët h∆°n GPU
GLOBAL_PREDICTION_DAYS = 10 # S·ªë ng√†y d·ª± b√°o
# --- H·∫æT PH·∫¶N BI·∫æN GLOBAL ---
# --- BI·∫æN GLOBAL CHO KHO·∫¢NG TH·ªúI GIAN ---
start_date = (datetime.now() - timedelta(days=365 * 10)).strftime("%Y-%m-%d")  # 10 nƒÉm tr∆∞·ªõc
end_date = datetime.now().strftime("%Y-%m-%d")
# --- H·∫æT PH·∫¶N BI·∫æN GLOBAL ---
# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng cho Google
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    print("Kh√¥ng t√¨m th·∫•y kh√≥a API Google. Vui l√≤ng ki·ªÉm tra file .env")
    exit()
# C·∫•u h√¨nh API client cho Google
genai.configure(api_key=GOOGLE_API_KEY)
# T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ d·ªØ li·ªáu
if not os.path.exists("vnstocks_data"):
    os.makedirs("vnstocks_data")
# ======================
# PH·∫¶N 1: THU TH·∫¨P D·ªÆ LI·ªÜU (C·∫¨P NH·∫¨T)
# ======================
def get_vnstocks_list():
    """L·∫•y danh s√°ch t·∫•t c·∫£ c√°c m√£ ch·ª©ng kho√°n tr√™n th·ªã tr∆∞·ªùng Vi·ªát Nam s·ª≠ d·ª•ng vnstock v2"""
    try:
        df = listing_companies()
        if df is not None and not df.empty:
            df = df[df["organType"] == "DN"]
            symbols = df[["ticker"]].rename(columns={"ticker": "symbol"})
            symbols.to_csv("vnstocks_data/stock_list.csv", index=False)
            print(f"ƒê√£ l∆∞u danh s√°ch {len(symbols)} m√£ ch·ª©ng kho√°n v√†o file 'vnstocks_data/stock_list.csv'")
            return symbols
        else:
            print("Kh√¥ng l·∫•y ƒë∆∞·ª£c danh s√°ch t·ª´ vnstock, s·ª≠ d·ª•ng danh s√°ch m·∫´u")
            sample_stocks = ["VNM", "VCB", "FPT", "GAS", "BID", "CTG", "MWG", "PNJ", "HPG", "STB"]
            df = pd.DataFrame(sample_stocks, columns=["symbol"])
            df.to_csv("vnstocks_data/stock_list.csv", index=False)
            return df
    except Exception as e:
        print(f"Exception khi l·∫•y danh s√°ch m√£: {str(e)}")
        sample_stocks = ["VNM", "VCB", "FPT", "GAS", "BID", "CTG", "MWG", "PNJ", "HPG", "STB"]
        df = pd.DataFrame(sample_stocks, columns=["symbol"])
        df.to_csv("vnstocks_data/stock_list.csv", index=False)
        return df
def get_stock_data(symbol):
    """L·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ c·ªßa m·ªôt m√£ ch·ª©ng kho√°n s·ª≠ d·ª•ng vnstock v2 m·ªõi theo t√†i li·ªáu"""
    try:
        quote = Quote(symbol)
        df = quote.history(start=start_date, end=end_date, interval="1D")
        if df is not None and not df.empty:
            df.rename(columns={"time": "Date", "open": "Open", "high": "High", "low": "Low", "close": "Close", "volume": "Volume"}, inplace=True)
            df["Date"] = pd.to_datetime(df["Date"])
            df.set_index("Date", inplace=True)
            df.sort_index(inplace=True)
            df.to_csv(f"vnstocks_data/{symbol}_data.csv")
            print(f"ƒê√£ l∆∞u d·ªØ li·ªáu cho m√£ {symbol} v√†o file 'vnstocks_data/{symbol}_data.csv'")
            return df
        else:
            print(f"Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu cho m√£ {symbol} t·ª´ vnstock")
            return None
    except Exception as e:
        print(f"Exception khi l·∫•y d·ªØ li·ªáu cho m√£ {symbol}: {str(e)}")
        return None
# ======================
# PH·∫¶N 1B: THU TH·∫¨P D·ªÆ LI·ªÜU BCTC (C·∫¨P NH·∫¨T)
# ======================
def get_financial_data(symbol):
    """L·∫•y d·ªØ li·ªáu b√°o c√°o t√†i ch√≠nh s·ª≠ d·ª•ng vnstock v2 - 12 qu√Ω g·∫ßn nh·∫•t"""
    try:
        financial_obj = Finance(symbol=symbol)
        # --- C·∫¨P NH·∫¨T: Th√™m tham s·ªë limit=12 ---
        financial_data = financial_obj.ratio(period="quarter", lang="en", flatten_columns=True, limit=12)
        # --- H·∫æT C·∫¨P NH·∫¨T ---
        if financial_data is not None and not financial_data.empty:
            financial_data.to_csv(f"vnstocks_data/{symbol}_financial.csv", index=False)
            return financial_data
        else:
            print(f"Kh√¥ng l·∫•y ƒë∆∞·ª£c BCTC cho m√£ {symbol}")
            return None
    except Exception as e:
        print(f"L·ªói khi l·∫•y BCTC cho {symbol}: {str(e)}")
        return None
def get_market_data():
    """L·∫•y d·ªØ li·ªáu th·ªã tr∆∞·ªùng t·ªïng th·ªÉ s·ª≠ d·ª•ng vnstock v2"""
    try:
        quoteVNI = Quote(symbol="VNINDEX")
        vnindex = quoteVNI.history(start=start_date, end=end_date, interval="1D")
        if vnindex is not None and not vnindex.empty:
            vnindex.rename(columns={"time": "Date", "open": "Open", "high": "High", "low": "Low", "close": "Close", "volume": "Volume"}, inplace=True)
            vnindex["Date"] = pd.to_datetime(vnindex["Date"])
            vnindex.set_index("Date", inplace=True)
            vnindex.sort_index(inplace=True)
            vnindex.to_csv("vnstocks_data/vnindex_data.csv")
        quoteVN30 = Quote(symbol="VN30")
        vn30 = quoteVN30.history(start=start_date, end=end_date, interval="1D")
        if vn30 is not None and not vn30.empty:
            vn30.rename(columns={"time": "Date", "open": "Open", "high": "High", "low": "Low", "close": "Close", "volume": "Volume"}, inplace=True)
            vn30["Date"] = pd.to_datetime(vn30["Date"])
            vn30.set_index("Date", inplace=True)
            vn30.sort_index(inplace=True)
            vn30.to_csv("vnstocks_data/vn30_data.csv")
        print("ƒê√£ l∆∞u d·ªØ li·ªáu ch·ªâ s·ªë th·ªã tr∆∞·ªùng v√†o th∆∞ m·ª•c 'vnstocks_data/'")
        return {"vnindex": vnindex, "vn30": vn30}
    except Exception as e:
        print(f"L·ªói khi l·∫•y d·ªØ li·ªáu th·ªã tr∆∞·ªùng: {str(e)}")
        return None
# ======================
# PH·∫¶N 2: TI·ªÄN X·ª¨ L√ù V√Ä T·∫†O ƒê·∫∂C TR∆ØNG
# ======================
def preprocess_stock_data(df):
    """Preprocesses raw stock data from vnstock"""
    df.index = pd.to_datetime(df.index)
    df.sort_index(ascending=True, inplace=True)
    df.ffill(inplace=True)
    df.bfill(inplace=True)
    df["returns"] = df["Close"].pct_change()
    df["MA_10"] = df["Close"].rolling(window=10).mean()
    df["MA_50"] = df["Close"].rolling(window=50).mean()
    df["volatility"] = df["returns"].rolling(window=10).std()
    df.dropna(inplace=True)
    return df
def create_features(df):
    """Generates technical indicators using pure pandas/numpy"""
    delta = df["Close"].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.rolling(window=14).mean()
    avg_loss = loss.rolling(window=14).mean()
    rs = avg_gain / avg_loss
    df["RSI"] = 100 - (100 / (1 + rs))
    ema12 = df["Close"].ewm(span=12, adjust=False).mean()
    ema26 = df["Close"].ewm(span=26, adjust=False).mean()
    df["MACD"] = ema12 - ema26
    df["MACD_signal"] = df["MACD"].ewm(span=9, adjust=False).mean()
    df["BB_middle"] = df["Close"].rolling(window=20).mean()
    df["BB_std"] = df["Close"].rolling(window=20).std()
    df["BB_upper"] = df["BB_middle"] + (df["BB_std"] * 2)
    df["BB_lower"] = df["BB_middle"] - (df["BB_std"] * 2)
    high_low = df["High"] - df["Low"]
    high_close = np.abs(df["High"] - df["Close"].shift())
    low_close = np.abs(df["Low"] - df["Close"].shift())
    true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df["ATR"] = true_range.rolling(window=14).mean()
    df["SMA_20"] = df["Close"].rolling(window=20).mean()
    df["EMA_50"] = df["Close"].ewm(span=50, adjust=False).mean()
    df["Momentum"] = df["Close"] / df["Close"].shift(4) - 1
    df["Volume_MA"] = df["Volume"].rolling(window=10).mean()
    df["Volume_Change"] = df["Volume"].pct_change()
    df.dropna(inplace=True)
    return df
# ======================
# PH·∫¶N 3A: M√î H√åNH AI - LSTM PYTORCH T·ªêI ∆ØU
# ======================
# --- C·∫¢I TI·∫æN 2: H√†m ki·ªÉm tra thi·∫øt b·ªã n√¢ng cao ---
def check_device_and_configure():
    """Ki·ªÉm tra v√† c·∫•u h√¨nh thi·∫øt b·ªã t·ªët nh·∫•t (MPS, CUDA, CPU) cho PyTorch."""
    print("Ki·ªÉm tra thi·∫øt b·ªã:")
    print(f"PyTorch version: {torch.__version__}")
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"‚úÖ CUDA GPU ƒë∆∞·ª£c ph√°t hi·ªán: {torch.cuda.get_device_name(0)}")
        print("C√°c thi·∫øt b·ªã CUDA kh·∫£ d·ª•ng:")
        for i in range(torch.cuda.device_count()):
            print(f"  {i}: {torch.cuda.get_device_name(i)}")
    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():
        device = torch.device("mps")
        print("‚úÖ MPS (Apple Silicon) ƒë∆∞·ª£c ph√°t hi·ªán v√† s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng.")
    else:
        device = torch.device("cpu")
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y GPU (CUDA/MPS), s·∫Ω s·ª≠ d·ª•ng CPU.")
    return device
# --- H·∫æT C·∫¢I TI·∫æN 2 ---
# --- C·∫¢I TI·∫æN 3: ƒê·ªãnh nghƒ©a m√¥ h√¨nh PyTorch c·∫£i ti·∫øn ---
class OptimizedLSTMModel(nn.Module):
    def __init__(self, input_size=1, hidden_layer_size=150, num_layers=4, output_size=1, dropout=0.2):
        super(OptimizedLSTMModel, self).__init__()
        self.hidden_layer_size = hidden_layer_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=num_layers, dropout=dropout, batch_first=True)
        self.dropout = nn.Dropout(dropout)
        self.fc1 = nn.Linear(hidden_layer_size, 75)
        self.fc2 = nn.Linear(75, output_size)
    def forward(self, input_seq):
        lstm_out, _ = self.lstm(input_seq)
        lstm_out = self.dropout(lstm_out[:, -1, :]) # L·∫•y output cu·ªëi c√πng
        out = torch.relu(self.fc1(lstm_out))
        out = self.dropout(out)
        predictions = self.fc2(out)
        return predictions
# --- H·∫æT C·∫¢I TI·∫æN 3 ---
# --- C·∫¢I TI·∫æN 4: H√†m hu·∫•n luy·ªán PyTorch t·ªëi ∆∞u ---
def train_stock_model_pytorch_optimized(df, target="Close", time_steps=60, test_size=0.2, epochs=GLOBAL_EPOCHS, batch_size=GLOBAL_BATCH_SIZE):
    """Hu·∫•n luy·ªán m√¥ h√¨nh LSTM PyTorch ƒë∆∞·ª£c t·ªëi ∆∞u."""
    try:
        if df is None or len(df) < time_steps: return None, None, None, None, None
        if target not in df.columns: return None, None, None, None, None
        data = df[[target]].values.astype(np.float32)
        data = data[np.isfinite(data)].reshape(-1, 1)
        if len(data) == 0: return None, None, None, None, None
        scaler = MinMaxScaler(feature_range=(0, 1))
        scaled_data = scaler.fit_transform(data)
        if len(scaled_data) <= time_steps: return None, None, None, None, None
        X, y = [], []
        for i in range(time_steps, len(scaled_data)):
            X.append(scaled_data[i - time_steps : i, 0])
            y.append(scaled_data[i, 0])
        if len(X) == 0 or len(y) == 0: return None, None, None, None, None
        X, y = np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)
        X = np.reshape(X, (X.shape[0], X.shape[1], 1))
        split_index = max(1, int(len(X) * (1 - test_size)))
        if split_index >= len(X): split_index = len(X) - 1
        X_train, X_test = X[:split_index], X[split_index:]
        y_train, y_test = y[:split_index], y[split_index:]
        if len(X_train) == 0 or len(y_train) == 0: return None, None, None, None, None
        device = check_device_and_configure()
        # S·ª≠ d·ª•ng DataLoader ƒë·ªÉ qu·∫£n l√Ω batch hi·ªáu qu·∫£ h∆°n
        train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=(device.type != 'cpu'))
        test_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=(device.type != 'cpu'))
        model = OptimizedLSTMModel(input_size=1, hidden_layer_size=150, num_layers=4, output_size=1, dropout=0.2)
        model.to(device)
        # C·ªë g·∫Øng compile model ƒë·ªÉ tƒÉng t·ªëc (n·∫øu h·ªó tr·ª£)
        try:
            model = torch.compile(model)
            print("‚úÖ Model ƒë√£ ƒë∆∞·ª£c compile ƒë·ªÉ tƒÉng hi·ªáu su·∫•t.")
        except Exception as e:
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ compile model: {e}")
        loss_function = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-7)
        early_stopping_patience = 10
        best_val_loss = float('inf')
        patience_counter = 0
        print(f"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh LSTM PyTorch t·ªëi ∆∞u v·ªõi {epochs} epochs v√† batch_size={batch_size}...")
        for epoch in range(epochs):
            model.train()
            epoch_loss = 0.0
            for batch_x, batch_y in train_loader:
                batch_x, batch_y = batch_x.to(device), batch_y.to(device)
                optimizer.zero_grad()
                with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')): # Mixed precision cho CUDA
                    y_pred = model(batch_x).squeeze()
                    loss = loss_function(y_pred, batch_y)
                scaler_loss = torch.cuda.amp.GradScaler() if device.type == 'cuda' else None
                if scaler_loss:
                    scaler_loss.scale(loss).backward()
                    scaler_loss.step(optimizer)
                    scaler_loss.update()
                else:
                    loss.backward()
                    optimizer.step()
                epoch_loss += loss.item()
            model.eval()
            val_loss = 0.0
            with torch.no_grad():
                for batch_x, batch_y in test_loader:
                    batch_x, batch_y = batch_x.to(device), batch_y.to(device)
                    with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):
                        y_pred = model(batch_x).squeeze()
                        loss = loss_function(y_pred, batch_y)
                    val_loss += loss.item() * batch_x.size(0) # Nh√¢n v·ªõi batch size ƒë·ªÉ t√≠nh trung b√¨nh ƒë√∫ng
            avg_val_loss = val_loss / len(test_loader.dataset)
            scheduler.step(avg_val_loss) # C·∫≠p nh·∫≠t learning rate d·ª±a tr√™n val loss
            avg_epoch_loss = epoch_loss / len(train_loader)
            print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_epoch_loss:.6f}, Val Loss: {avg_val_loss:.6f}, LR: {optimizer.param_groups[0]["lr"]:.2e}')
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                patience_counter = 0
                # L∆∞u model t·ªët nh·∫•t
                torch.save(model.state_dict(), f'vnstocks_data/best_model_{df.index.name if df.index.name else "unknown"}.pth')
            else:
                patience_counter += 1
                if patience_counter >= early_stopping_patience:
                    print("Early stopping triggered.")
                    break
        print("‚úÖ Hu·∫•n luy·ªán m√¥ h√¨nh LSTM PyTorch t·ªëi ∆∞u ho√†n t·∫•t")
        model.eval()
        y_pred_list, y_test_list = [], []
        with torch.no_grad():
            for batch_x, batch_y in test_loader:
                batch_x = batch_x.to(device)
                with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):
                    y_pred = model(batch_x).cpu().numpy()
                y_pred_list.append(y_pred)
                y_test_list.append(batch_y.numpy())
        y_pred_all = np.concatenate(y_pred_list)
        y_test_all = np.concatenate(y_test_list)
        y_pred_inv = scaler.inverse_transform(y_pred_all)
        y_test_inv = scaler.inverse_transform(y_test_all.reshape(-1, 1))
        try:
            mse = mean_squared_error(y_test_inv, y_pred_inv)
            rmse_val = np.sqrt(mse)
            mae_val = mean_absolute_error(y_test_inv, y_pred_inv)
            r2 = r2_score(y_test_inv, y_pred_inv)
            print("\n--- ƒê√ÅNH GI√Å M√î H√åNH D·ª∞ B√ÅO ---")
            print(f"RMSE: {rmse_val:.2f}")
            print(f"MAE: {mae_val:.2f}")
            print(f"R2: {r2:.2f}")
            print("--- H·∫æT ƒê√ÅNH GI√Å ---\n")
        except Exception as e:
            print(f"L·ªói khi t√≠nh to√°n ƒë√°nh gi√° LSTM PyTorch: {str(e)}")
            mse, rmse_val, mae_val, r2 = 0, 0, 0, 0
        return model, scaler, None, y_test_inv, y_pred_inv # Tr·∫£ v·ªÅ None cho X_test_tensor v√¨ kh√¥ng c√≤n d√πng
    except Exception as e:
        print(f"L·ªói nghi√™m tr·ªçng khi hu·∫•n luy·ªán m√¥ h√¨nh LSTM PyTorch t·ªëi ∆∞u: {str(e)}")
        traceback.print_exc()
        return None, None, None, None, None
# --- H·∫æT C·∫¢I TI·∫æN 4 ---
# --- C·∫¢I TI·∫æN 5: H√†m d·ª± b√°o PyTorch t·ªëi ∆∞u (ƒê√É S·ª¨A) ---
def predict_next_days_pytorch_optimized(model, scaler, df, target="Close", time_steps=60, n_days=GLOBAL_PREDICTION_DAYS):
    """D·ª± b√°o gi√° trong n ng√†y ti·∫øp theo (cho LSTM PyTorch t·ªëi ∆∞u)"""
    try:
        if model is None or scaler is None or df is None:
            print("D·ªØ li·ªáu ƒë·∫ßu v√†o kh√¥ng h·ª£p l·ªá cho PyTorch predict")
            return np.array([]), np.array([])
        if target not in df.columns:
            print(f"C·ªôt {target} kh√¥ng t·ªìn t·∫°i")
            return np.array([]), np.array([])
        if len(df) < time_steps:
            print("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ d·ª± b√°o")
            return np.array([]), np.array([])
        
        # --- B∆Ø·ªöC 1: L·∫§Y D·ªÆ LI·ªÜU CU·ªêI C√ôNG ƒê√öNG C√ÅCH ---
        # L·∫•y d·ªØ li·ªáu cu·ªëi c√πng (time_steps ƒëi·ªÉm g·∫ßn nh·∫•t)
        last_data = df[target].values[-time_steps:]
        # Ki·ªÉm tra xem c√≥ NaN hay kh√¥ng
        if pd.isna(last_data).any():
            # N·∫øu c√≥ NaN, c·∫ßn x·ª≠ l√Ω (fill forward/backward ho·∫∑c b·ªè qua)
            # D∆∞·ªõi ƒë√¢y l√† fill forward
            last_data_series = pd.Series(last_data)
            last_data_series = last_data_series.fillna(method='ffill').fillna(method='bfill')
            last_data = last_data_series.values
        
        # ƒê·∫£m b·∫£o d·ªØ li·ªáu c√≥ ƒë·ªß chi·ªÅu d√†i
        if len(last_data) != time_steps:
            print(f"L·ªói: Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ d·ª± b√°o ({len(last_data)} ƒëi·ªÉm, c·∫ßn {time_steps} ƒëi·ªÉm)")
            return np.array([]), np.array([])
        
        # --- B∆Ø·ªöC 2: CHU·∫®N H√ìA D·ªÆ LI·ªÜU ---
        # Chu·∫©n h√≥a b·∫±ng scaler ƒë√£ d√πng khi hu·∫•n luy·ªán
        try:
            # Chuy·ªÉn th√†nh array 2D ƒë·ªÉ ph√π h·ª£p v·ªõi scaler.transform
            last_data_reshaped = last_data.reshape(-1, 1)
            last_data_scaled = scaler.transform(last_data_reshaped)
            # Tr·ªü l·∫°i d·∫°ng 1D ƒë·ªÉ ƒë∆∞a v√†o m√¥ h√¨nh
            last_data_scaled_flat = last_data_scaled.flatten()
        except Exception as e:
            print(f"L·ªói khi chu·∫©n h√≥a d·ªØ li·ªáu d·ª± b√°o: {str(e)}")
            return np.array([]), np.array([])
        
        # --- B∆Ø·ªöC 3: D·ª∞ B√ÅO ---
        forecast_scaled = []
        model.eval()
        device = next(model.parameters()).device # L·∫•y thi·∫øt b·ªã t·ª´ model
        with torch.no_grad():
            # Chu·∫©n b·ªã input tensor (1 batch, time_steps, 1 feature)
            x_input = torch.tensor(last_data_scaled_flat.reshape(1, time_steps, 1), dtype=torch.float32).to(device)
            
            for _ in range(n_days):
                with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):
                    pred = model(x_input)
                forecast_scaled.append(pred.item())
                # C·∫≠p nh·∫≠t input cho b∆∞·ªõc d·ª± b√°o ti·∫øp theo
                # L·∫•y ph·∫ßn c√≤n l·∫°i c·ªßa chu·ªói c≈© v√† n·ªëi v·ªõi d·ª± b√°o m·ªõi
                x_input = torch.cat((x_input[:, 1:, :], pred.reshape(1, 1, 1)), dim=1)
        
        # --- B∆Ø·ªöC 4: CHUY·ªÇN ƒê·ªîI GI√Å TR·ªû L·∫†I ---
        try:
            # Chuy·ªÉn ƒë·ªïi sang gi√° tr·ªã th·ª±c
            forecast_values = scaler.inverse_transform(np.array(forecast_scaled).reshape(-1, 1)).flatten()
        except Exception as e:
            print(f"L·ªói khi chuy·ªÉn ƒë·ªïi gi√° g·ªëc: {str(e)}")
            return np.array([]), np.array([])
        
        # --- B∆Ø·ªöC 5: T·∫†O NG√ÄY D·ª∞ B√ÅO ---
        last_date = df.index[-1]
        forecast_dates = [last_date + timedelta(days=i + 1) for i in range(n_days)]
        
        return np.array(forecast_dates), forecast_values
    except Exception as e:
        print(f"L·ªói nghi√™m tr·ªçng khi d·ª± b√°o PyTorch t·ªëi ∆∞u: {str(e)}")
        traceback.print_exc()
        return np.array([]), np.array([])
# --- H·∫æT C·∫¢I TI·∫æN 5 ---
# --- C·∫¨P NH·∫¨T H√ÄM ƒê√ÅNH GI√Å D·ªÆ LI·ªÜU (CHO LSTM) ---
def evaluate_data_for_ai(df_features, symbol):
    """ƒê√°nh gi√° d·ªØ li·ªáu ƒë·ªÉ ƒë·ªÅ xu·∫•t m√¥ h√¨nh AI ph√π h·ª£p (ch·ªâ LSTM)."""
    if df_features is None or len(df_features) == 0:
        print(f"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√° cho m√£ {symbol}.")
        return "Kh√¥ng x√°c ƒë·ªãnh", "Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·∫ßu v√†o."
    num_points = len(df_features)
    num_features = len(df_features.columns)
    print(f"--- ƒê√ÅNH GI√Å D·ªÆ LI·ªÜU CHO M√É {symbol} ---")
    print(f"S·ªë ƒëi·ªÉm d·ªØ li·ªáu: {num_points}")
    print(f"S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng: {num_features}")
    if num_points > 2500: # Ng∆∞·ª°ng cao h∆°n m·ªôt ch√∫t
        recommendation = "LSTM PYTORCH T·ªêI ∆ØU"
        reason = f"D·ªØ li·ªáu phong ph√∫ ({num_points} ƒëi·ªÉm), LSTM PYTORCH T·ªêI ∆ØU s·∫Ω ph√°t huy hi·ªáu qu·∫£ cao."
    elif num_points > 1500:
        recommendation = "LSTM PYTORCH T·ªêI ∆ØU"
        reason = f"D·ªØ li·ªáu ·ªïn ƒë·ªãnh ({num_points} ƒëi·ªÉm), LSTM PYTORCH T·ªêI ∆ØU l√† l·ª±a ch·ªçn ph√π h·ª£p."
    elif num_features > 60:
        recommendation = "LSTM PYTORCH T·ªêI ∆ØU"
        reason = f"D·ªØ li·ªáu ƒëa chi·ªÅu ({num_features} ƒë·∫∑c tr∆∞ng), LSTM PYTORCH T·ªêI ∆ØU c√≥ kh·∫£ nƒÉng x·ª≠ l√Ω t·ªët."
    else:
        recommendation = "LSTM PYTORCH T·ªêI ∆ØU"
        reason = f"D·ªØ li·ªáu ti√™u chu·∫©n ({num_points} ƒëi·ªÉm, {num_features} ƒë·∫∑c tr∆∞ng), LSTM PYTORCH T·ªêI ∆ØU ƒë·∫£m b·∫£o hi·ªáu su·∫•t & ƒë·ªô ch√≠nh x√°c."
    print(f"üí° ƒê·ªÅ xu·∫•t m√¥ h√¨nh AI: {recommendation}")
    print(f"‚ùì L√Ω do: {reason}")
    print("--- H·∫æT ƒê√ÅNH GI√Å ---")
    return recommendation, reason

# ======================
# PH·∫¶N 3B: M√î H√åNH AI - N-BEATS (B·ªî SUNG)
# ======================

# --- TH√äM: ƒê·ªãnh nghƒ©a m√¥ h√¨nh N-BEATS ---
class NBeatsBlock(nn.Module):
    def __init__(self, input_size: int, theta_size: int, basis_function, layers: int, layer_size: int):
        super().__init__()
        self.input_size = input_size
        self.theta_size = theta_size
        self.basis_function = basis_function
        self.layers = nn.ModuleList([nn.Linear(in_features=input_size, out_features=layer_size)] +
                                    [nn.Linear(in_features=layer_size, out_features=layer_size)
                                     for _ in range(layers - 1)])
        self.basis_parameters = nn.Linear(in_features=layer_size, out_features=theta_size)
        self.relu = nn.ReLU()

    def forward(self, x):
        block_input = x
        for layer in self.layers:
            block_input = self.relu(layer(block_input))
        basis_parameters = self.basis_parameters(block_input)
        return self.basis_function(basis_parameters)


def seasonality_model(thetas, t, device):
    p = thetas.size()[-1]
    assert p <= thetas.shape[1], "Nhi·ªÅu tham s·ªë h∆°n c√°c b∆∞·ªõc th·ªùi gian"
    p1, p2 = (p // 2, p // 2) if p % 2 == 0 else (p // 2, p // 2 + 1)
    s1 = torch.tensor([torch.cos(2 * torch.pi * i * t) for i in range(p1)]).float().to(device)
    s2 = torch.tensor([torch.sin(2 * torch.pi * i * t) for i in range(p2)]).float().to(device)
    S = torch.cat([s1, s2], dim=0) # ƒê·∫£m b·∫£o k√≠ch th∆∞·ªõc ƒë√∫ng
    # T√≠nh to√°n theo batch
    return torch.sum(thetas.unsqueeze(-1) * S.unsqueeze(0), dim=1)


def trend_model(thetas, t, device):
    p = thetas.size()[-1]
    assert p <= thetas.shape[1], "Nhi·ªÅu tham s·ªë h∆°n c√°c b∆∞·ªõc th·ªùi gian"
    T = torch.tensor([t ** i for i in range(p)]).float().to(device)
    # T√≠nh to√°n theo batch
    return torch.sum(thetas.unsqueeze(-1) * T.unsqueeze(0), dim=1)


class NBeats(nn.Module):
    def __init__(self, device, input_size: int = 60, output_size: int = 10,
                 stacks: int = 3, blocks_per_stack: int = 1,
                 forecast_length: int = GLOBAL_PREDICTION_DAYS, backcast_length: int = None, # Cho ph√©p None
                 thetas_dims: list = [4, 8], share_weights_in_stack: bool = False,
                 hidden_layer_units: int = 256):
        super(NBeats, self).__init__()
        self.device = device
        self.forecast_length = forecast_length
        # X·ª≠ l√Ω backcast_length: n·∫øu None th√¨ d√πng input_size, ƒë·∫£m b·∫£o input_size l√† s·ªë nguy√™n h·ª£p l·ªá
        if backcast_length is None:
            if not isinstance(input_size, int) or input_size <= 0:
                 raise ValueError(f"input_size ph·∫£i l√† s·ªë nguy√™n d∆∞∆°ng n·∫øu backcast_length kh√¥ng ƒë∆∞·ª£c cung c·∫•p. Nh·∫≠n ƒë∆∞·ª£c input_size={input_size}")
            self.backcast_length = input_size
        else:
            if not isinstance(backcast_length, int) or backcast_length <= 0:
                raise ValueError(f"backcast_length ph·∫£i l√† s·ªë nguy√™n d∆∞∆°ng. Nh·∫≠n ƒë∆∞·ª£c backcast_length={backcast_length}")
            self.backcast_length = backcast_length
            
        # Ki·ªÉm tra input_size c√≥ kh·ªõp v·ªõi backcast_length kh√¥ng?
        # Trong h·∫ßu h·∫øt c√°c tr∆∞·ªùng h·ª£p, input_size n√™n b·∫±ng backcast_length
        # C√≥ th·ªÉ th√™m c·∫£nh b√°o n·∫øu ch√∫ng kh√°c nhau, nh∆∞ng ·ªü ƒë√¢y ta ∆∞u ti√™n backcast_length
        if input_size != self.backcast_length:
             print(f"C·∫£nh b√°o: input_size ({input_size}) kh√°c v·ªõi backcast_length ({self.backcast_length}). D√πng backcast_length cho t√≠nh to√°n.")

        self.hidden_layer_units = hidden_layer_units
        self.stacks = stacks
        self.blocks_per_stack = blocks_per_stack
        self.share_weights_in_stack = share_weights_in_stack

        # T·∫°o tensor th·ªùi gian cho trend v√† seasonality
        # ƒê·∫£m b·∫£o r·∫±ng c√°c gi√° tr·ªã n√†y l√† s·ªë nguy√™n tr∆∞·ªõc khi truy·ªÅn cho linspace
        forecast_steps = int(self.forecast_length)
        backcast_steps = int(self.backcast_length)
        
        if forecast_steps <= 0:
            raise ValueError(f"forecast_length ph·∫£i l√† s·ªë nguy√™n d∆∞∆°ng sau khi chuy·ªÉn ƒë·ªïi. Nh·∫≠n ƒë∆∞·ª£c forecast_length={forecast_length}")
        if backcast_steps <= 0:
            raise ValueError(f"backcast_length (sau khi x·ª≠ l√Ω) ph·∫£i l√† s·ªë nguy√™n d∆∞∆°ng. Nh·∫≠n ƒë∆∞·ª£c backcast_length={backcast_length}, input_size={input_size}")

        self.t_forecast = torch.linspace(0, 1, forecast_steps).to(self.device) # [forecast_length]
        self.t_backcast = torch.linspace(0, 1, backcast_steps).to(self.device) # [backcast_length]

        self.stack_list = nn.ModuleList()

        # Stack 1: Seasonality
        for _ in range(blocks_per_stack):
            block = NBeatsBlock(input_size=self.backcast_length, theta_size=thetas_dims[0],
                                basis_function=lambda thetas: seasonality_model(thetas, self.t_forecast, self.device),
                                layers=4, layer_size=hidden_layer_units)
            self.stack_list.append(block)

        # Stack 2: Trend
        for _ in range(blocks_per_stack):
            block = NBeatsBlock(input_size=self.backcast_length, theta_size=thetas_dims[1],
                                basis_function=lambda thetas: trend_model(thetas, self.t_forecast, self.device),
                                layers=4, layer_size=hidden_layer_units)
            self.stack_list.append(block)

        # Stack 3: Generic
        for _ in range(blocks_per_stack):
            block = NBeatsBlock(input_size=self.backcast_length,
                                theta_size=self.forecast_length + self.backcast_length,
                                basis_function=lambda thetas: thetas[:, :self.forecast_length], # Forecast part
                                layers=4, layer_size=hidden_layer_units)
            self.stack_list.append(block)

    def forward(self, x):
        # Ki·ªÉm tra k√≠ch th∆∞·ªõc ƒë·∫ßu v√†o
        if x.dim() != 2:
            raise ValueError(f"ƒê·∫ßu v√†o x ph·∫£i c√≥ 2 chi·ªÅu [batch, seq_len], nh∆∞ng nh·∫≠n ƒë∆∞·ª£c {x.dim()} chi·ªÅu")
        if x.size(1) != self.backcast_length:
            raise ValueError(f"Chi·ªÅu d√†i chu·ªói ƒë·∫ßu v√†o ({x.size(1)}) ph·∫£i b·∫±ng backcast_length ({self.backcast_length})")
            
        # Chu·∫©n h√≥a ƒë·∫ßu v√†o
        x_mean = torch.mean(x, dim=1, keepdim=True) # [batch, 1]
        x_centered = x - x_mean # [batch, backcast_length]
        # Kh·ªüi t·∫°o backcast v√† forecast
        backcast = x_centered # [batch, backcast_length]
        forecast = torch.zeros(size=(x.size(0), self.forecast_length), device=self.device) # [batch, forecast_length]
        # Forward qua c√°c stack
        for i, block in enumerate(self.stack_list):
            # block_input = backcast # [batch, backcast_length]
            block_forecast = block(backcast) # [batch, forecast_length] ho·∫∑c [batch, theta_size]
            if i < self.blocks_per_stack: # Seasonality
                 block_backcast = seasonality_model(block.basis_parameters(block.layers[-1](block.relu(block.layers[0](backcast)))), self.t_backcast, self.device) # T√≠nh l·∫°i backcast t·ª´ theta
            elif i < 2 * self.blocks_per_stack: # Trend
                 block_backcast = trend_model(block.basis_parameters(block.layers[-1](block.relu(block.layers[0](backcast)))), self.t_backcast, self.device) # T√≠nh l·∫°i backcast t·ª´ theta
            else: # Generic
                 theta_full = block.basis_parameters(block.layers[-1](block.relu(block.layers[0](backcast)))) # [batch, theta_size]
                 block_backcast = theta_full[:, self.forecast_length:] # [batch, backcast_length]
                 # block_forecast ƒë√£ ƒë∆∞·ª£c t√≠nh trong block.forward
            backcast = backcast - block_backcast # [batch, backcast_length]
            forecast = forecast + block_forecast # [batch, forecast_length]
        # Th√™m l·∫°i gi√° tr·ªã trung b√¨nh
        forecast = forecast + x_mean # [batch, forecast_length]
        return forecast

# --- H·∫æT TH√äM: ƒê·ªãnh nghƒ©a m√¥ h√¨nh N-BEATS ---

# --- TH√äM: H√†m hu·∫•n luy·ªán N-BEATS ---
def train_stock_model_nbeats(df, target="Close", time_steps=60, test_size=0.2, epochs=GLOBAL_EPOCHS, batch_size=GLOBAL_BATCH_SIZE):
    """Hu·∫•n luy·ªán m√¥ h√¨nh N-BEATS."""
    try:
        if df is None or len(df) < time_steps: return None, None, None, None, None
        if target not in df.columns: return None, None, None, None, None
        data = df[[target]].values.astype(np.float32)
        data = data[np.isfinite(data)].reshape(-1, 1)
        if len(data) == 0: return None, None, None, None, None
        scaler = MinMaxScaler(feature_range=(0, 1))
        scaled_data = scaler.fit_transform(data)
        if len(scaled_data) <= time_steps: return None, None, None, None, None
        X, y = [], []
        for i in range(time_steps, len(scaled_data) - GLOBAL_PREDICTION_DAYS + 1): # ƒêi·ªÅu ch·ªânh ƒë·ªÉ l·∫•y chu·ªói d·ª± b√°o
            X.append(scaled_data[i - time_steps : i, 0])
            y.append(scaled_data[i : i + GLOBAL_PREDICTION_DAYS, 0]) # D·ª± b√°o nhi·ªÅu ng√†y
        if len(X) == 0 or len(y) == 0: return None, None, None, None, None
        X, y = np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)
        # Kh√¥ng c·∫ßn reshape cho N-BEATS, n√≥ l√†m vi·ªác v·ªõi (batch, seq_len)
        split_index = max(1, int(len(X) * (1 - test_size)))
        if split_index >= len(X): split_index = len(X) - 1
        X_train, X_test = X[:split_index], X[split_index:]
        y_train, y_test = y[:split_index], y[split_index:]
        if len(X_train) == 0 or len(y_train) == 0: return None, None, None, None, None
        device = check_device_and_configure() # S·ª≠ d·ª•ng h√†m ki·ªÉm tra thi·∫øt b·ªã chung
        train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=(device.type != 'cpu'))
        test_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=(device.type != 'cpu'))
        model = NBeats(device=device, input_size=time_steps, output_size=GLOBAL_PREDICTION_DAYS)
        model.to(device)
        try:
            model = torch.compile(model)
            print("‚úÖ N-BEATS Model ƒë√£ ƒë∆∞·ª£c compile ƒë·ªÉ tƒÉng hi·ªáu su·∫•t.")
        except Exception as e:
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ compile N-BEATS model: {e}")
        loss_function = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-7)
        early_stopping_patience = 10
        best_val_loss = float('inf')
        patience_counter = 0
        print(f"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh N-BEATS v·ªõi {epochs} epochs v√† batch_size={batch_size}...")
        for epoch in range(epochs):
            model.train()
            epoch_loss = 0.0
            for batch_x, batch_y in train_loader:
                batch_x, batch_y = batch_x.to(device), batch_y.to(device)
                optimizer.zero_grad()
                with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):
                    y_pred = model(batch_x)
                    loss = loss_function(y_pred, batch_y)
                scaler_loss = torch.cuda.amp.GradScaler() if device.type == 'cuda' else None
                if scaler_loss:
                    scaler_loss.scale(loss).backward()
                    scaler_loss.step(optimizer)
                    scaler_loss.update()
                else:
                    loss.backward()
                    optimizer.step()
                epoch_loss += loss.item()
            model.eval()
            val_loss = 0.0
            with torch.no_grad():
                for batch_x, batch_y in test_loader:
                    batch_x, batch_y = batch_x.to(device), batch_y.to(device)
                    with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):
                        y_pred = model(batch_x)
                        loss = loss_function(y_pred, batch_y)
                    val_loss += loss.item() * batch_x.size(0)
            avg_val_loss = val_loss / len(test_loader.dataset)
            scheduler.step(avg_val_loss)
            avg_epoch_loss = epoch_loss / len(train_loader)
            print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_epoch_loss:.6f}, Val Loss: {avg_val_loss:.6f}, LR: {optimizer.param_groups[0]["lr"]:.2e}')
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                patience_counter = 0
                torch.save(model.state_dict(), f'vnstocks_data/best_model_nbeats_{df.index.name if df.index.name else "unknown"}.pth')
            else:
                patience_counter += 1
                if patience_counter >= early_stopping_patience:
                    print("Early stopping triggered cho N-BEATS.")
                    break
        print("‚úÖ Hu·∫•n luy·ªán m√¥ h√¨nh N-BEATS ho√†n t·∫•t")
        model.eval()
        y_pred_list, y_test_list = [], []
        with torch.no_grad():
            for batch_x, batch_y in test_loader:
                batch_x = batch_x.to(device)
                with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):
                    y_pred = model(batch_x).cpu().numpy()
                y_pred_list.append(y_pred)
                y_test_list.append(batch_y.numpy())
        y_pred_all = np.concatenate(y_pred_list, axis=0)
        y_test_all = np.concatenate(y_test_list, axis=0)
        # Ch·ªâ l·∫•y gi√° tr·ªã cu·ªëi c√πng ƒë·ªÉ so s√°nh RMSE/MAE/R2 (ho·∫∑c c√≥ th·ªÉ t√≠nh trung b√¨nh l·ªói cho to√†n chu·ªói)
        y_pred_last = y_pred_all[:, -1].reshape(-1, 1) # D·ª± b√°o ng√†y cu·ªëi c√πng
        y_test_last = y_test_all[:, -1].reshape(-1, 1) # Gi√° tr·ªã th·ª±c t·∫ø ng√†y cu·ªëi c√πng
        y_pred_inv_last = scaler.inverse_transform(y_pred_last)
        y_test_inv_last = scaler.inverse_transform(y_test_last)
        try:
            mse = mean_squared_error(y_test_inv_last, y_pred_inv_last)
            rmse_val = np.sqrt(mse)
            mae_val = mean_absolute_error(y_test_inv_last, y_pred_inv_last)
            r2 = r2_score(y_test_inv_last, y_pred_inv_last)
            print("\n--- ƒê√ÅNH GI√Å M√î H√åNH D·ª∞ B√ÅO N-BEATS (Ng√†y cu·ªëi) ---")
            print(f"RMSE (Ng√†y cu·ªëi): {rmse_val:.2f}")
            print(f"MAE (Ng√†y cu·ªëi): {mae_val:.2f}")
            print(f"R2 (Ng√†y cu·ªëi): {r2:.2f}")
            print("--- H·∫æT ƒê√ÅNH GI√Å ---\n")
        except Exception as e:
            print(f"L·ªói khi t√≠nh to√°n ƒë√°nh gi√° N-BEATS: {str(e)}")
            mse, rmse_val, mae_val, r2 = 0, 0, 0, 0
        # Tr·∫£ v·ªÅ to√†n b·ªô d·ª± b√°o ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì
        # Chuy·ªÉn ƒë·ªïi ng∆∞·ª£c to√†n b·ªô chu·ªói d·ª± b√°o
        y_pred_full_inv = scaler.inverse_transform(y_pred_all.reshape(-1, GLOBAL_PREDICTION_DAYS)).reshape(y_pred_all.shape)
        y_test_full_inv = scaler.inverse_transform(y_test_all.reshape(-1, GLOBAL_PREDICTION_DAYS)).reshape(y_test_all.shape)

        return model, scaler, None, y_test_full_inv, y_pred_full_inv
    except Exception as e:
        print(f"L·ªói nghi√™m tr·ªçng khi hu·∫•n luy·ªán m√¥ h√¨nh N-BEATS: {str(e)}")
        traceback.print_exc()
        return None, None, None, None, None
# --- H·∫æT TH√äM: H√†m hu·∫•n luy·ªán N-BEATS ---

# --- TH√äM: H√†m d·ª± b√°o N-BEATS ---
def predict_next_days_nbeats(model, scaler, df, target="Close", time_steps=60, n_days=GLOBAL_PREDICTION_DAYS):
    """D·ª± b√°o gi√° trong n ng√†y ti·∫øp theo (cho N-BEATS)"""
    try:
        if model is None or scaler is None or df is None:
            print("D·ªØ li·ªáu ƒë·∫ßu v√†o kh√¥ng h·ª£p l·ªá cho N-BEATS predict")
            return np.array([]), np.array([])
        if target not in df.columns:
            print(f"C·ªôt {target} kh√¥ng t·ªìn t·∫°i")
            return np.array([]), np.array([])
        if len(df) < time_steps:
            print("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ d·ª± b√°o")
            return np.array([]), np.array([])
        last_data = df[target].values[-time_steps:]
        last_data = last_data[np.isfinite(last_data)]
        if len(last_data) < time_steps:
            print("D·ªØ li·ªáu kh√¥ng ƒë·ªß sau khi lo·∫°i b·ªè NaN")
            return np.array([]), np.array([])
        try:
            last_data_scaled = scaler.transform(last_data.reshape(-1, 1)).flatten() # ƒê·∫£m b·∫£o l√† 1D array
        except Exception as e:
            print(f"L·ªói khi chu·∫©n h√≥a d·ªØ li·ªáu d·ª± b√°o N-BEATS: {str(e)}")
            return np.array([]), np.array([])
        model.eval()
        device = next(model.parameters()).device # L·∫•y thi·∫øt b·ªã t·ª´ model
        with torch.no_grad():
            x_input = torch.tensor(last_data_scaled.reshape(1, time_steps), dtype=torch.float32).to(device)
            with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):
                forecast_scaled = model(x_input).cpu().numpy().flatten() # D·ª± b√°o cho n_days
        try:
            # N-BEATS tr·∫£ v·ªÅ tr·ª±c ti·∫øp chu·ªói d·ª± b√°o, kh√¥ng c·∫ßn n·ªëi th√™m
            forecast = scaler.inverse_transform(forecast_scaled.reshape(-1, 1)).flatten()
        except Exception as e:
            print(f"L·ªói khi chuy·ªÉn ƒë·ªïi gi√° g·ªëc N-BEATS: {str(e)}")
            return np.array([]), np.array([])
        last_date = df.index[-1]
        forecast_dates = [last_date + timedelta(days=i + 1) for i in range(n_days)]
        return np.array(forecast_dates), forecast
    except Exception as e:
        print(f"L·ªói nghi√™m tr·ªçng khi d·ª± b√°o N-BEATS: {str(e)}")
        traceback.print_exc()
        return np.array([]), np.array([])
# --- H·∫æT TH√äM: H√†m d·ª± b√°o N-BEATS ---

# --- C·∫¨P NH·∫¨T H√ÄM ƒê√ÅNH GI√Å D·ªÆ LI·ªÜU (CHO N-BEATS) ---
def evaluate_data_for_ai_nbeats(df_features, symbol):
    """ƒê√°nh gi√° d·ªØ li·ªáu ƒë·ªÉ ƒë·ªÅ xu·∫•t m√¥ h√¨nh AI ph√π h·ª£p (N-BEATS)."""
    if df_features is None or len(df_features) == 0:
        print(f"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√° cho m√£ {symbol}.")
        return "Kh√¥ng x√°c ƒë·ªãnh", "Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·∫ßu v√†o."
    num_points = len(df_features)
    num_features = len(df_features.columns)
    print(f"--- ƒê√ÅNH GI√Å D·ªÆ LI·ªÜU CHO M√É {symbol} (N-BEATS) ---")
    print(f"S·ªë ƒëi·ªÉm d·ªØ li·ªáu: {num_points}")
    print(f"S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng: {num_features}")
    # N-BEATS th∆∞·ªùng ho·∫°t ƒë·ªông t·ªët v·ªõi chu·ªói th·ªùi gian d√†i
    if num_points > 3000:
        recommendation = "N-BEATS"
        reason = f"D·ªØ li·ªáu r·∫•t phong ph√∫ ({num_points} ƒëi·ªÉm), N-BEATS c√≥ th·ªÉ t·∫≠n d·ª•ng t·ªët."
    elif num_points > 2000:
        recommendation = "N-BEATS"
        reason = f"D·ªØ li·ªáu phong ph√∫ ({num_points} ƒëi·ªÉm), N-BEATS l√† l·ª±a ch·ªçn ph√π h·ª£p."
    else:
        recommendation = "LSTM PYTORCH T·ªêI ∆ØU" # M·∫∑c ƒë·ªãnh n·∫øu d·ªØ li·ªáu kh√¥ng ƒë·ªß cho N-BEATS
        reason = f"D·ªØ li·ªáu ({num_points} ƒëi·ªÉm) c√≥ th·ªÉ ph√π h·ª£p h∆°n v·ªõi LSTM PYTORCH T·ªêI ∆ØU."
    print(f"üí° ƒê·ªÅ xu·∫•t m√¥ h√¨nh AI: {recommendation}")
    print(f"‚ùì L√Ω do: {reason}")
    print("--- H·∫æT ƒê√ÅNH GI√Å ---")
    return recommendation, reason
# --- H·∫æT C·∫¨P NH·∫¨T H√ÄM ƒê√ÅNH GI√Å D·ªÆ LI·ªÜU ---

# ======================
# PH·∫¶N 4: PH√ÇN T√çCH K·ª∏ THU·∫¨T C·∫¢I TI·∫æN
# ======================
def plot_stock_analysis(symbol, df, show_volume=True):
    """Ph√¢n t√≠ch k·ªπ thu·∫≠t v√† v·∫Ω bi·ªÉu ƒë·ªì cho m√£ ch·ª©ng kho√°n"""
    try:
        if df is None or len(df) == 0:
            print("D·ªØ li·ªáu ph√¢n t√≠ch r·ªóng")
            return {"signal": "L·ªñI", "score": 50, "current_price": 0, "rsi_value": 0, "ma10": 0, "ma20": 0, "ma50": 0, "ma200": 0, "rs": 1.0, "rs_point": 0, "recommendation": "KH√îNG X√ÅC ƒê·ªäNH"}
        df = df.sort_index()
        # --- B∆Ø·ªöC 1: T√≠nh c√°c ch·ªâ b√°o k·ªπ thu·∫≠t ---
        df["SMA_10"] = ta.trend.sma_indicator(df["Close"], window=10)
        df["SMA_20"] = ta.trend.sma_indicator(df["Close"], window=20)
        df["SMA_50"] = ta.trend.sma_indicator(df["Close"], window=50)
        df["SMA_200"] = ta.trend.sma_indicator(df["Close"], window=200)
        df["RSI"] = ta.momentum.rsi(df["Close"], window=14)
        macd = ta.trend.MACD(df["Close"])
        df["MACD"] = macd.macd()
        df["MACD_Signal"] = macd.macd_signal()
        df["MACD_Hist"] = macd.macd_diff()
        bollinger = ta.volatility.BollingerBands(df["Close"])
        df["BB_Upper"] = bollinger.bollinger_hband()
        df["BB_Lower"] = bollinger.bollinger_lband()
        df["Volume_SMA_20"] = ta.trend.sma_indicator(df["Volume"], window=20)
        df["Volume_SMA_50"] = ta.trend.sma_indicator(df["Volume"], window=50)
        tenkan_window = 9
        kijun_window = 26
        senkou_span_b_window = 52
        tenkan_sen_high = df["High"].rolling(window=tenkan_window).max()
        tenkan_sen_low = df["Low"].rolling(window=tenkan_window).min()
        df["ichimoku_tenkan_sen"] = (tenkan_sen_high + tenkan_sen_low) / 2
        kijun_sen_high = df["High"].rolling(window=kijun_window).max()
        kijun_sen_low = df["Low"].rolling(window=kijun_window).min()
        df["ichimoku_kijun_sen"] = (kijun_sen_high + kijun_sen_low) / 2
        df["ichimoku_senkou_span_a"] = ((df["ichimoku_tenkan_sen"] + df["ichimoku_kijun_sen"]) / 2).shift(kijun_window)
        senkou_span_b_high = df["High"].rolling(window=senkou_span_b_window).max()
        senkou_span_b_low = df["Low"].rolling(window=senkou_span_b_window).min()
        df["ichimoku_senkou_span_b"] = ((senkou_span_b_high + senkou_span_b_low) / 2).shift(kijun_window)
        df["ichimoku_chikou_span"] = df["Close"].shift(-kijun_window)
        # --- B∆Ø·ªöC 2: T√≠nh RS (Relative Strength so v·ªõi VNINDEX) theo c√¥ng th·ª©c Amibroker ---
        try:
            quoteVNI = Quote(symbol="VNINDEX")
            vnindex_df = quoteVNI.history(start=start_date, end=end_date, interval="1D")
            if len(vnindex_df) == 0: raise ValueError("Kh√¥ng l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu VNINDEX")
            vnindex_df.rename(columns={"time": "Date", "open": "Open", "high": "High", "low": "Low", "close": "Close", "volume": "Volume"}, inplace=True)
            vnindex_df["Date"] = pd.to_datetime(vnindex_df["Date"])
            vnindex_df.set_index("Date", inplace=True)
            vnindex_df.sort_index(inplace=True)
            df_merged = df[["Close"]].join(vnindex_df[["Close"]].rename(columns={"Close": "VNINDEX_Close"}), how="left")
            if df_merged["VNINDEX_Close"].isna().all():
                df["RS"] = 1.0
                df["RS_Point"] = 0.0
                print("C·∫£nh b√°o: Kh√¥ng c√≥ d·ªØ li·ªáu VNINDEX, b·ªè qua RS")
            else:
                df_merged["VNINDEX_Close"] = df_merged["VNINDEX_Close"].ffill()
                price_return = df_merged["Close"] / df_merged["Close"].shift(1)
                index_return = df_merged["VNINDEX_Close"] / df_merged["VNINDEX_Close"].shift(1)
                df["RS"] = price_return / index_return
                roc_63 = ta.momentum.roc(df["Close"], window=63)
                roc_126 = ta.momentum.roc(df["Close"], window=126)
                roc_189 = ta.momentum.roc(df["Close"], window=189)
                roc_252 = ta.momentum.roc(df["Close"], window=252)
                df["RS_Point"] = (roc_63.fillna(0) * 0.4 + roc_126.fillna(0) * 0.2 + roc_189.fillna(0) * 0.2 + roc_252.fillna(0) * 0.2) * 100
                df["RS_Point_SMA_10"] = ta.trend.sma_indicator(df["RS_Point"], window=10)
                df["RS_Point_SMA_20"] = ta.trend.sma_indicator(df["RS_Point"], window=20)
                df["RS_Point_SMA_50"] = ta.trend.sma_indicator(df["RS_Point"], window=50)
                df["RS_Point_SMA_200"] = ta.trend.sma_indicator(df["RS_Point"], window=200)
                df["RS_SMA_10"] = ta.trend.sma_indicator(df["RS"], window=10)
                df["RS_SMA_20"] = ta.trend.sma_indicator(df["RS"], window=20)
                df["RS_SMA_50"] = ta.trend.sma_indicator(df["RS"], window=50)
                df["RS_SMA_200"] = ta.trend.sma_indicator(df["RS"], window=200)
        except Exception as e:
            print(f"Kh√¥ng th·ªÉ t√≠nh RS do l·ªói VNINDEX: {e}")
            df["RS"] = 1.0
            df["RS_Point"] = 0.0
            df["RS_SMA_10"] = 1.0
            df["RS_SMA_20"] = 1.0
            df["RS_SMA_50"] = 1.0
            df["RS_SMA_200"] = 1.0
            df["RS_Point_SMA_10"] = 0.0
            df["RS_Point_SMA_20"] = 0.0
            df["RS_Point_SMA_50"] = 0.0
            df["RS_Point_SMA_200"] = 0.0
        # --- B∆Ø·ªöC 3: Ki·ªÉm tra d·ªØ li·ªáu h·ª£p l·ªá ---
        df = df.dropna(subset=["Close", "SMA_10", "SMA_20", "SMA_50"], how="all")
        if len(df) < 20:
            print("Kh√¥ng ƒë·ªß d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ ph√¢n t√≠ch")
            return {"signal": "L·ªñI", "score": 50, "current_price": df["Close"].iloc[-1] if len(df) > 0 else 0, "rsi_value": 50, "ma10": df["Close"].iloc[-1] if len(df) > 0 else 0, "ma20": df["Close"].iloc[-1] if len(df) > 0 else 0, "ma50": df["Close"].iloc[-1] if len(df) > 0 else 0, "ma200": df["Close"].iloc[-1] if len(df) > 0 else 0, "rs": 1.0, "rs_point": 0, "recommendation": "KH√îNG X√ÅC ƒê·ªäNH"}
      # --- B∆Ø·ªöC 4: V·∫Ω bi·ªÉu ƒë·ªì (C·∫¨P NH·∫¨T) ---
        # --- B∆Ø·ªöC 4: V·∫Ω bi·ªÉu ƒë·ªì (C·∫¨P NH·∫¨T) ---
        try:
            plot_configs = ["price_sma", "ichimoku", "rsi", "macd", "rs", "rs_point", "volume"]
            num_subplots = len(plot_configs)
            height_per_subplot = 3
            width = 18
            height = num_subplots * height_per_subplot
            plt.figure(figsize=(width, height), constrained_layout=True)
            # ƒêi·ªÅu ch·ªânh GridSpec - TƒÇNG K√çCH TH∆Ø·ªöC CHO RSI & MACD
            # height_ratios: [Price, Ichimoku, RSI, MACD, RS, RS_Point, Volume, (placeholder)]
            grid = plt.GridSpec(
                8, 1, hspace=0.3, height_ratios=[3, 3, 2, 2, 2, 2, 2, 2]
            )
            # === Bi·ªÉu ƒë·ªì 1: Gi√° v√† c√°c ƒë∆∞·ªùng trung b√¨nh ===
            ax1 = plt.subplot(grid[0])
            plt.plot(df.index, df["Close"], label=f"Gi√° ƒë√≥ng c·ª≠a {df['Close'].iloc[-1]:,.2f}", color="#1f77b4", linewidth=1.5)
            plt.plot(df.index, df["SMA_10"], label=f"SMA 10 {df['SMA_10'].iloc[-1]:,.2f}", color="blue", alpha=0.7, linewidth=1)
            plt.plot(df.index, df["SMA_20"], label=f"SMA 20 {df['SMA_20'].iloc[-1]:,.2f}", color="orange", alpha=0.8, linewidth=1.5)
            plt.plot(df.index, df["SMA_50"], label=f"SMA 50 {df['SMA_50'].iloc[-1]:,.2f}", color="green", alpha=0.8, linewidth=1.5)
            plt.plot(df.index, df["SMA_200"], label=f"SMA 200 {df['SMA_200'].iloc[-1]:,.2f}", color="purple", alpha=0.8, linewidth=1.5)
            plt.plot(df.index, df["BB_Upper"], label=f"BB Upper {df['BB_Upper'].iloc[-1]:,.2f}", color="red", alpha=0.5, linestyle="--")
            plt.plot(df.index, df["BB_Lower"], label=f"BB Lower {df['BB_Lower'].iloc[-1]:,.2f}", color="green", alpha=0.5, linestyle="--")
            plt.fill_between(df.index, df["BB_Lower"], df["BB_Upper"], color="gray", alpha=0.1)
            cross_10_20_above = (df["SMA_10"] > df["SMA_20"]) & (df["SMA_10"].shift(1) <= df["SMA_20"].shift(1))
            cross_10_20_below = (df["SMA_10"] < df["SMA_20"]) & (df["SMA_10"].shift(1) >= df["SMA_20"].shift(1))
            if cross_10_20_above.any():
                plt.scatter(df.index[cross_10_20_above], df.loc[cross_10_20_above, "SMA_10"], marker="^", color="lime", s=60, label="SMA10 > SMA20", zorder=5)
            if cross_10_20_below.any():
                plt.scatter(df.index[cross_10_20_below], df.loc[cross_10_20_below, "SMA_10"], marker="v", color="magenta", s=60, label="SMA10 < SMA20", zorder=5)
            plt.suptitle(f"Ph√¢n t√≠ch k·ªπ thu·∫≠t {symbol} - Gi√° v√† Ch·ªâ b√°o", fontsize=16, fontweight="bold", y=0.98)
            plt.ylabel("Gi√° (VND)", fontsize=12)
            plt.legend(loc="upper left", fontsize=10)
            plt.grid(True, alpha=0.3)
            # === Bi·ªÉu ƒë·ªì 2: Ichimoku Cloud ===
            ax2 = plt.subplot(grid[1], sharex=ax1)
            for i in range(len(df)):
                if i < len(df) - 1:
                    date = mdates.date2num(df.index[i])
                    open_price = (df["Open"].iloc[i] if not pd.isna(df["Open"].iloc[i]) else df["Close"].iloc[i])
                    high_price = (df["High"].iloc[i] if not pd.isna(df["High"].iloc[i]) else df["Close"].iloc[i])
                    low_price = (df["Low"].iloc[i] if not pd.isna(df["Low"].iloc[i]) else df["Close"].iloc[i])
                    close_price = (df["Close"].iloc[i] if not pd.isna(df["Close"].iloc[i]) else open_price)
                    if close_price >= open_price:
                        color = "green"
                        bottom = open_price
                        height = close_price - open_price
                    else:
                        color = "red"
                        bottom = close_price
                        height = open_price - close_price
                    if height > 0:
                        plt.bar(date, height, bottom=bottom, color=color, width=0.6, alpha=0.8)
                    plt.plot([date, date], [low_price, high_price], color="black", linewidth=0.5)
            plt.plot(df.index, df["ichimoku_tenkan_sen"], label=f"Tenkan-sen {df['ichimoku_tenkan_sen'].iloc[-1]:,.2f}", color="red", linewidth=1)
            plt.plot(df.index, df["ichimoku_kijun_sen"], label=f"Kijun-sen {df['ichimoku_kijun_sen'].iloc[-1]:,.2f}", color="blue", linewidth=1)
            plt.plot(df.index, df["ichimoku_senkou_span_a"], label=f"Senkou Span A {df['ichimoku_senkou_span_a'].iloc[-1]:,.2f}", color="green", linewidth=1, alpha=0.7)
            plt.plot(df.index, df["ichimoku_senkou_span_b"], label=f"Senkou Span B {df['ichimoku_senkou_span_b'].iloc[-1]:,.2f}", color="purple", linewidth=1, alpha=0.7)
            plt.plot(df.index, df["ichimoku_chikou_span"], label=f"Chikou Span {df['ichimoku_chikou_span'].iloc[-1]:,.2f}", color="orange", linewidth=1)
            valid_cloud = (df["ichimoku_senkou_span_a"].notna() & df["ichimoku_senkou_span_b"].notna())
            if valid_cloud.any():
                plt.fill_between(df.index[valid_cloud], df["ichimoku_senkou_span_a"][valid_cloud], df["ichimoku_senkou_span_b"][valid_cloud], where=(df["ichimoku_senkou_span_a"][valid_cloud] >= df["ichimoku_senkou_span_b"][valid_cloud]), color="green", alpha=0.2, interpolate=True, label="Bullish Cloud")
                plt.fill_between(df.index[valid_cloud], df["ichimoku_senkou_span_a"][valid_cloud], df["ichimoku_senkou_span_b"][valid_cloud], where=(df["ichimoku_senkou_span_a"][valid_cloud] < df["ichimoku_senkou_span_b"][valid_cloud]), color="red", alpha=0.2, interpolate=True, label="Bearish Cloud")
            plt.plot(df.index, df["Close"], label="Gi√° ƒë√≥ng c·ª≠a", color="black", linewidth=1.5, alpha=0.7)
            plt.title("Ichimoku Cloud", fontsize=12)
            plt.ylabel("Gi√°", fontsize=10)
            plt.legend(fontsize=7, loc="upper left", ncol=2)
            plt.grid(True, alpha=0.3)
            # === Bi·ªÉu ƒë·ªì 3: RSI ===
            ax3 = plt.subplot(grid[2], sharex=ax1)
            plt.plot(df.index, df["RSI"], label=f"RSI {df['RSI'].iloc[-1]:.2f}", color="purple")
            plt.axhline(70, linestyle="--", color="red", alpha=0.7)
            plt.axhline(30, linestyle="--", color="green", alpha=0.7)
            plt.fill_between(df.index, 30, 70, color="gray", alpha=0.1)
            plt.title("RSI", fontsize=12)
            plt.ylabel("RSI", fontsize=10)
            plt.grid(True, alpha=0.3)
            plt.legend(fontsize=7, loc="upper left")
            # === Bi·ªÉu ƒë·ªì 4: MACD ===
            ax4 = plt.subplot(grid[3], sharex=ax1)
            plt.plot(df.index, df["MACD"], label=f"MACD {df['MACD'].iloc[-1]:.2f}", color="blue")
            plt.plot(df.index, df["MACD_Signal"], label=f"Signal Line {df['MACD_Signal'].iloc[-1]:.2f}", color="red")
            # Ch·ªâ v·∫Ω histogram b·∫±ng bar, kh√¥ng c·∫ßn plot th√™m line cho hist
            plt.bar(df.index, df["MACD_Hist"], color=np.where(df["MACD_Hist"] > 0, "green", "red"), alpha=0.5, label=f"Hist {df['MACD_Hist'].iloc[-1]:.2f}")
            plt.title("MACD", fontsize=12)
            plt.ylabel("MACD", fontsize=10)
            plt.legend(fontsize=7, loc="upper left")
            plt.grid(True, alpha=0.3)
            # === Bi·ªÉu ƒë·ªì 5: RS (Relative Strength vs VNINDEX) ===
            ax5 = plt.subplot(grid[4], sharex=ax1)
            plt.plot(df.index, df["RS"], label=f"RS (Price / VNINDEX) {df['RS'].iloc[-1]:.2f}", color="brown", linewidth=1.5)
            plt.plot(df.index, df["RS_SMA_10"], label=f"RS SMA 10 {df['RS_SMA_10'].iloc[-1]:.2f}", color="blue", alpha=0.7, linewidth=1)
            plt.plot(df.index, df["RS_SMA_20"], label=f"RS SMA 20 {df['RS_SMA_20'].iloc[-1]:.2f}", color="orange", alpha=0.7, linewidth=1)
            plt.plot(df.index, df["RS_SMA_50"], label=f"RS SMA 50 {df['RS_SMA_50'].iloc[-1]:.2f}", color="green", alpha=0.7, linewidth=1)
            plt.plot(df.index, df["RS_SMA_200"], label=f"RS SMA 200 {df['RS_SMA_200'].iloc[-1]:.2f}", color="purple", alpha=0.7, linewidth=1)
            plt.title("RS vs VNINDEX", fontsize=12)
            plt.ylabel("RS", fontsize=10)
            plt.grid(True, alpha=0.3)
            plt.legend(fontsize=7, loc="upper left")
            # === Bi·ªÉu ƒë·ªì 6: RS_Point ===
            ax6 = plt.subplot(grid[5], sharex=ax1)
            plt.plot(df.index, df["RS_Point"], label=f"RS_Point {df['RS_Point'].iloc[-1]:.2f}", color="darkblue", linewidth=1.5)
            plt.plot(df.index, df["RS_Point_SMA_10"], label=f"RS_Point SMA 10 {df['RS_Point_SMA_10'].iloc[-1]:.2f}", color="blue", alpha=0.7, linewidth=1)
            plt.plot(df.index, df["RS_Point_SMA_20"], label=f"RS_Point SMA 20 {df['RS_Point_SMA_20'].iloc[-1]:.2f}", color="orange", alpha=0.7, linewidth=1)
            plt.plot(df.index, df["RS_Point_SMA_50"], label=f"RS_Point SMA 50 {df['RS_Point_SMA_50'].iloc[-1]:.2f}", color="green", alpha=0.7, linewidth=1)
            plt.plot(df.index, df["RS_Point_SMA_200"], label=f"RS_Point SMA 200 {df['RS_Point_SMA_200'].iloc[-1]:.2f}", color="purple", alpha=0.7, linewidth=1)
            plt.axhline(0, color="black", linestyle="-", linewidth=0.8)
            plt.fill_between(df.index, df["RS_Point"], 0, where=(df["RS_Point"] > 0), color="green", alpha=0.3)
            plt.fill_between(df.index, df["RS_Point"], 0, where=(df["RS_Point"] < 0), color="red", alpha=0.3)
            plt.title("RS_Point", fontsize=12)
            plt.ylabel("RS_Point", fontsize=10)
            plt.grid(True, alpha=0.3)
            plt.legend(fontsize=7, loc="upper left")
            # === Bi·ªÉu ƒë·ªì 7: Kh·ªëi l∆∞·ª£ng ===
            ax7 = plt.subplot(grid[6], sharex=ax1)
            if show_volume and "Volume" in df.columns:
                volume_sma_plotted = False
                if ("Volume_SMA_20" in df.columns and not df["Volume_SMA_20"].isna().all()):
                    plt.plot(df.index, df["Volume_SMA_20"], label=f"Vol SMA 20 {df['Volume_SMA_20'].iloc[-1]:,.0f}", color="orange", alpha=0.8, linewidth=1.5)
                    volume_sma_plotted = True
                if ("Volume_SMA_50" in df.columns and not df["Volume_SMA_50"].isna().all()):
                    plt.plot(df.index, df["Volume_SMA_50"], label=f"Vol SMA 50 {df['Volume_SMA_50'].iloc[-1]:,.0f}", color="purple", alpha=0.8, linewidth=1.5)
                    volume_sma_plotted = True
                colors = np.where(df["Close"] > df["Open"], "green", "red")
                plt.bar(df.index, df["Volume"], color=colors, alpha=0.7, label="Volume" if not volume_sma_plotted else None)
                handles, labels = ax7.get_legend_handles_labels()
                if handles:
                    by_label = dict(zip(labels, handles))
                    plt.legend(by_label.values(), by_label.keys(), loc="upper left")
                else:
                    plt.legend(fontsize=7, loc="upper left")
                plt.title("Volume & Vol SMA", fontsize=12)
                plt.ylabel("Kh·ªëi l∆∞·ª£ng", fontsize=10)
                plt.grid(True, alpha=0.3)
            else:
                plt.title("Kh·ªëi l∆∞·ª£ng giao d·ªãch", fontsize=12)
                plt.ylabel("Kh·ªëi l∆∞·ª£ng", fontsize=10)
                plt.grid(True, alpha=0.3)
            # ƒêi·ªÅu ch·ªânh layout ƒë·ªÉ tr√°nh ch·ªìng ch·ªØ
            plt.tight_layout(pad=3.0, h_pad=1.0)
            plt.subplots_adjust(top=0.95, bottom=0.08, left=0.08, right=0.97, hspace=0.4)
            # L∆∞u bi·ªÉu ƒë·ªì
            plt.savefig(f"vnstocks_data/{symbol}_technical_analysis.png", dpi=300, bbox_inches="tight")
            plt.close()
            print(f"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì ph√¢n t√≠ch k·ªπ thu·∫≠t v√†o vnstocks_data/{symbol}_technical_analysis.png")
        except Exception as e:
            print(f"‚ùå L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì: {str(e)}")
            import traceback
            traceback.print_exc() # In traceback ƒë·∫ßy ƒë·ªß ƒë·ªÉ d·ªÖ g·ª° l·ªói
        # --- B∆Ø·ªöC 5: T·∫°o t√≠n hi·ªáu giao d·ªãch (C·∫¢I TI·∫æN LOGIC) ---
        try:
            last_row = df.iloc[-1]
            current_price = last_row["Close"]
            rsi_value = last_row["RSI"] if not pd.isna(last_row["RSI"]) else 50
            ma10_value = (last_row["SMA_10"] if not pd.isna(last_row["SMA_10"]) else current_price)
            ma20_value = (last_row["SMA_20"] if not pd.isna(last_row["SMA_20"]) else current_price)
            ma50_value = (last_row["SMA_50"] if not pd.isna(last_row["SMA_50"]) else current_price)
            ma200_value = (last_row["SMA_200"] if not pd.isna(last_row["SMA_200"]) else current_price)
            rs_value = last_row["RS"] if not pd.isna(last_row["RS"]) else 1.0
            rs_point_value = (last_row["RS_Point"] if not pd.isna(last_row["RS_Point"]) else 0)
            tenkan_sen = last_row.get("ichimoku_tenkan_sen", np.nan)
            kijun_sen = last_row.get("ichimoku_kijun_sen", np.nan)
            senkou_span_a = last_row.get("ichimoku_senkou_span_a", np.nan)
            senkou_span_b = last_row.get("ichimoku_senkou_span_b", np.nan)
            chikou_span = last_row.get("ichimoku_chikou_span", np.nan)
            # --- H·ªÜ TH·ªêNG T√çNH ƒêI·ªÇM TO√ÄN DI·ªÜN C·∫¢I TI·∫æN ---
            score = 50 # ƒêi·ªÉm c∆° b·∫£n
            # 1. RSI - 15 ƒëi·ªÉm
            if rsi_value < 30: score += 15
            elif rsi_value > 70: score -= 15
            else: score += (50 - abs(rsi_value - 50)) * 0.3
            # 2. ƒê∆∞·ªùng trung b√¨nh - 25 ƒëi·ªÉm (TƒÉng tr·ªçng s·ªë)
            if ma10_value > ma20_value > ma50_value > ma200_value: score += 25 # Xu h∆∞·ªõng tƒÉng m·∫°nh
            elif ma10_value > ma20_value > ma50_value: score += 15 # Xu h∆∞·ªõng tƒÉng trung b√¨nh
            elif ma10_value > ma20_value: score += 8 # Xu h∆∞·ªõng tƒÉng y·∫øu
            elif ma10_value < ma20_value < ma50_value < ma200_value: score -= 25 # Xu h∆∞·ªõng gi·∫£m m·∫°nh
            elif ma10_value < ma20_value < ma50_value: score -= 15 # Xu h∆∞·ªõng gi·∫£m trung b√¨nh
            elif ma10_value < ma20_value: score -= 8 # Xu h∆∞·ªõng gi·∫£m y·∫øu
            # 3. Gi√° so v·ªõi c√°c ƒë∆∞·ªùng trung b√¨nh - 10 ƒëi·ªÉm
            if current_price > ma10_value: score += 3
            if current_price > ma20_value: score += 3
            if current_price > ma50_value: score += 2
            if current_price > ma200_value: score += 2
            # 4. MACD - 15 ƒëi·ªÉm (TƒÉng tr·ªçng s·ªë)
            macd_value = last_row["MACD"] if not pd.isna(last_row["MACD"]) else 0
            macd_signal = (last_row["MACD_Signal"] if not pd.isna(last_row["MACD_Signal"]) else 0)
            macd_hist = (last_row["MACD_Hist"] if not pd.isna(last_row["MACD_Hist"]) else 0)
            # S·ª≠a l·ªói: Chuy·ªÉn ƒë·ªïi sang Series ƒë·ªÉ c√≥ th·ªÉ d√πng .shift()
            macd_hist_series = df["MACD_Hist"]
            if len(macd_hist_series) > 1:
                macd_hist_prev = macd_hist_series.iloc[-2] if not pd.isna(macd_hist_series.iloc[-2]) else 0
            else:
                macd_hist_prev = 0

            if macd_value > macd_signal and macd_hist > 0 and macd_hist > macd_hist_prev: score += 15 # T√≠n hi·ªáu mua m·∫°nh
            elif macd_value > macd_signal and macd_hist > 0: score += 10 # T√≠n hi·ªáu mua
            elif macd_value < macd_signal and macd_hist < 0 and macd_hist < macd_hist_prev: score -= 15 # T√≠n hi·ªáu b√°n m·∫°nh
            elif macd_value < macd_signal and macd_hist < 0: score -= 10 # T√≠n hi·ªáu b√°n
            else: score += np.clip(macd_hist * 40, -5, 5) # D·ª±a tr√™n histogram
            # 5. Bollinger Bands - 10 ƒëi·ªÉm
            bb_upper = (last_row["BB_Upper"] if not pd.isna(last_row["BB_Upper"]) else current_price)
            bb_lower = (last_row["BB_Lower"] if not pd.isna(last_row["BB_Lower"]) else current_price)
            if current_price > bb_upper: score -= 5 # Qu√° mua
            elif current_price < bb_lower: score += 5 # Qu√° b√°n
            else:
                bb_position = (current_price - bb_lower) / (bb_upper - bb_lower)
                score += (bb_position - 0.5) * 10
            # 6. RS (Relative Strength) - 10 ƒëi·ªÉm
            rs_score = 0
            if rs_value > last_row.get("RS_SMA_10", rs_value): rs_score += 2
            if rs_value > last_row.get("RS_SMA_20", rs_value): rs_score += 3
            if rs_value > last_row.get("RS_SMA_50", rs_value): rs_score += 5
            score += rs_score
            # 7. RS_Point - 10 ƒëi·ªÉm
            rs_point_score = 0
            if rs_point_value > last_row.get("RS_Point_SMA_10", rs_point_value): rs_point_score += 2
            if rs_point_value > last_row.get("RS_Point_SMA_20", rs_point_value): rs_point_score += 3
            if rs_point_value > last_row.get("RS_Point_SMA_50", rs_point_value): rs_point_score += 5
            score += rs_point_score
            # 8. Ichimoku Cloud - 15 ƒëi·ªÉm (TƒÉng tr·ªçng s·ªë)
            ichimoku_score = 0
            try:
                if not (pd.isna(tenkan_sen) or pd.isna(kijun_sen) or pd.isna(senkou_span_a) or pd.isna(senkou_span_b)):
                    cloud_top = max(senkou_span_a, senkou_span_b)
                    cloud_bottom = min(senkou_span_a, senkou_span_b)
                    if current_price > cloud_top and tenkan_sen > kijun_sen: ichimoku_score += 15 # Mua m·∫°nh
                    elif current_price > cloud_top: ichimoku_score += 10 # Mua
                    elif current_price < cloud_bottom and tenkan_sen < kijun_sen: ichimoku_score -= 15 # B√°n m·∫°nh
                    elif current_price < cloud_bottom: ichimoku_score -= 10 # B√°n
                    if tenkan_sen > kijun_sen: ichimoku_score += 5
                    elif tenkan_sen < kijun_sen: ichimoku_score -= 5
                    if kijun_sen > cloud_top: ichimoku_score += 5
                    elif kijun_sen < cloud_bottom: ichimoku_score -= 5
            except Exception as e: print(f"C·∫£nh b√°o: L·ªói khi t√≠nh ƒëi·ªÉm Ichimoku: {e}")
            score += ichimoku_score
            score = np.clip(score, 0, 100)
            # --- X√ÅC ƒê·ªäNH T√çN HI·ªÜU ---
            signal = "TRUNG L·∫¨P"
            recommendation = "GI·ªÆ"
            if score >= 80: signal = "MUA M·∫†NH"; recommendation = "MUA M·∫†NH"
            elif score >= 65: signal = "MUA"; recommendation = "MUA"
            elif score <= 20: signal = "B√ÅN M·∫†NH"; recommendation = "B√ÅN M·∫†NH"
            elif score <= 35: signal = "B√ÅN"; recommendation = "B√ÅN"
            analysis_date = df.index[-1].strftime("%d/%m/%Y")
            print(f"üìä T√çN HI·ªÜU GIAO D·ªäCH CU·ªêI ({analysis_date}):")
            print(f"  - Gi√° & ƒê∆∞·ªùng trung b√¨nh: Gi√°={current_price:,.2f} | SMA10={ma10_value:,.2f} | SMA20={ma20_value:,.2f} | SMA50={ma50_value:,.2f} | SMA200={ma200_value:,.2f}")
            try:
                print(f"  - Ichimoku:")
                print(f"    * Tenkan-sen: {tenkan_sen:.2f} | Kijun-sen: {kijun_sen:.2f}")
                print(f"    * Cloud (A/B): {senkou_span_a:.2f} / {senkou_span_b:.2f}")
                print(f"    * Chikou Span: {chikou_span:.2f}")
                print(f"    * ƒêi·ªÉm Ichimoku: ~{ichimoku_score:.1f}")
            except: print(f"  - Ichimoku: Kh√¥ng c√≥ d·ªØ li·ªáu")
            print(f"  - ƒê·ªÅ xu·∫•t: {recommendation} (ƒêi·ªÉm: {score:.1f})")
            # --- B∆Ø·ªöC 6: Tr·∫£ v·ªÅ k·∫øt qu·∫£ ph√¢n t√≠ch v·ªõi nhi·ªÅu th√¥ng tin h∆°n ---
            def safe_float(val):
                """Chuy·ªÉn ƒë·ªïi gi√° tr·ªã sang float, x·ª≠ l√Ω NaN/None."""
                try:
                    if pd.isna(val): return None
                    return float(val)
                except (TypeError, ValueError): return None
            return {
                "signal": signal, "score": float(score), "current_price": float(current_price), "rsi_value": float(rsi_value),
                "ma10": float(ma10_value), "ma20": float(ma20_value), "ma50": float(ma50_value), "ma200": float(ma200_value),
                "rs": float(rs_value), "rs_point": float(rs_point_value), "recommendation": recommendation,
                "open": safe_float(last_row.get("Open")), "high": safe_float(last_row.get("High")), "low": safe_float(last_row.get("Low")), "volume": safe_float(last_row.get("Volume")),
                "macd": safe_float(macd_value), "macd_signal": safe_float(macd_signal), "macd_hist": safe_float(macd_hist),
                "bb_upper": safe_float(bb_upper), "bb_lower": safe_float(bb_lower),
                "volume_sma_20": safe_float(last_row.get("Volume_SMA_20")), "volume_sma_50": safe_float(last_row.get("Volume_SMA_50")),
                "ichimoku_tenkan_sen": safe_float(tenkan_sen), "ichimoku_kijun_sen": safe_float(kijun_sen),
                "ichimoku_senkou_span_a": safe_float(senkou_span_a), "ichimoku_senkou_span_b": safe_float(senkou_span_b),
                "ichimoku_chikou_span": safe_float(chikou_span),
                "rs_sma_10": safe_float(last_row.get("RS_SMA_10")), "rs_sma_20": safe_float(last_row.get("RS_SMA_20")),
                "rs_sma_50": safe_float(last_row.get("RS_SMA_50")), "rs_sma_200": safe_float(last_row.get("RS_SMA_200")),
                "rs_point_sma_10": safe_float(last_row.get("RS_Point_SMA_10")), "rs_point_sma_20": safe_float(last_row.get("RS_Point_SMA_20")),
                "rs_point_sma_50": safe_float(last_row.get("RS_Point_SMA_50")), "rs_point_sma_200": safe_float(last_row.get("RS_Point_SMA_200")),
            }
        except Exception as e:
            print(f"‚ùå L·ªói khi t·∫°o t√≠n hi·ªáu: {str(e)}")
            traceback.print_exc() # In traceback ƒë·ªÉ d·ªÖ debug
            return {"signal": "L·ªñI", "score": 50, "current_price": df["Close"].iloc[-1] if len(df) > 0 else 0, "rsi_value": 50, "ma10": df["Close"].iloc[-1] if len(df) > 0 else 0, "ma20": df["Close"].iloc[-1] if len(df) > 0 else 0, "ma50": df["Close"].iloc[-1] if len(df) > 0 else 0, "ma200": df["Close"].iloc[-1] if len(df) > 0 else 0, "rs": 1.0, "rs_point": 0, "recommendation": "KH√îNG X√ÅC ƒê·ªäNH", "open": None, "high": None, "low": None, "volume": None, "macd": None, "macd_signal": None, "macd_hist": None, "bb_upper": None, "bb_lower": None, "volume_sma_20": None, "volume_sma_50": None, "ichimoku_tenkan_sen": None, "ichimoku_kijun_sen": None, "ichimoku_senkou_span_a": None, "ichimoku_senkou_span_b": None, "ichimoku_chikou_span": None, "rs_sma_10": None, "rs_sma_20": None, "rs_sma_50": None, "rs_sma_200": None, "rs_point_sma_10": None, "rs_point_sma_20": None, "rs_point_sma_50": None, "rs_point_sma_200": None}
    except Exception as e:
        print(f"‚ùå L·ªói nghi√™m tr·ªçng: {str(e)}")
        traceback.print_exc()
        return {"signal": "L·ªñI", "score": 50, "current_price": 0, "rsi_value": 0, "ma10": 0, "ma20": 0, "ma50": 0, "ma200": 0, "rs": 1.0, "rs_point": 0, "recommendation": "KH√îNG X√ÅC ƒê·ªäNH", "open": None, "high": None, "low": None, "volume": None, "macd": None, "macd_signal": None, "macd_hist": None, "bb_upper": None, "bb_lower": None, "volume_sma_20": None, "volume_sma_50": None, "ichimoku_tenkan_sen": None, "ichimoku_kijun_sen": None, "ichimoku_senkou_span_a": None, "ichimoku_senkou_span_b": None, "ichimoku_chikou_span": None, "rs_sma_10": None, "rs_sma_20": None, "rs_sma_50": None, "rs_sma_200": None, "rs_point_sma_10": None, "rs_point_sma_20": None, "rs_point_sma_50": None, "rs_point_sma_200": None}
# ======================
# PH·∫¶N 5: T√çCH H·ª¢P PH√ÇN T√çCH B·∫∞NG Google
# ======================
def analyze_with_gemini(symbol, trading_signal, forecast, financial_data=None):
    """Ph√¢n t√≠ch c·ªï phi·∫øu b·∫±ng Google Qwen d·ª±a tr√™n d·ªØ li·ªáu k·ªπ thu·∫≠t v√† BCTC"""
    try:
        def safe_format(val, fmt=".2f"):
            try:
                if val is None: return "N/A"
                if isinstance(val, float): 
                    if pd.isna(val) or np.isinf(val): return "N/A"
                return f"{{:{fmt}}}".format(float(val))
            except (ValueError, TypeError): return "N/A"
        rs_val = trading_signal["rs"]
        rs_sma10_val = trading_signal.get("rs_sma_10")
        rs_sma20_val = trading_signal.get("rs_sma_20")
        rs_sma50_val = trading_signal.get("rs_sma_50")
        rs_sma200_val = trading_signal.get("rs_sma_200")
        rs_point_val = trading_signal["rs_point"]
        rs_point_sma10_val = safe_format(trading_signal.get("rs_point_sma_10"), ".2f")
        rs_point_sma20_val = safe_format(trading_signal.get("rs_point_sma_20"), ".2f")
        rs_point_sma50_val = safe_format(trading_signal.get("rs_point_sma_50"), ".2f")
        rs_point_sma200_val = safe_format(trading_signal.get("rs_point_sma_200"), ".2f")
        tenkan_val = safe_format(trading_signal.get("ichimoku_tenkan_sen"))
        kijun_val = safe_format(trading_signal.get("ichimoku_kijun_sen"))
        senkou_a_val = safe_format(trading_signal.get("ichimoku_senkou_span_a"))
        senkou_b_val = safe_format(trading_signal.get("ichimoku_senkou_span_b"))
        chikou_val = safe_format(trading_signal.get("ichimoku_chikou_span"))
        # --- C·∫¢I TI·∫æN LOGIC T·∫†O PROMPT ---
        prompt = f"""
B·∫°n l√† chuy√™n gia ph√¢n t√≠ch ch·ª©ng kho√°n Vi·ªát Nam. Ph√¢n t√≠ch {symbol}:
1. K·ªπ thu·∫≠t:
- Gi√°: {trading_signal['current_price']:,.2f} VND
- RSI: {trading_signal['rsi_value']:.2f}
- MA10: {trading_signal['ma10']:,.2f} VND
- MA20: {trading_signal['ma20']:,.2f} VND
- MA50: {trading_signal['ma50']:,.2f} VND
- MA200: {trading_signal['ma200']:,.2f} VND
- BB: {safe_format(trading_signal.get('bb_upper'))} / {safe_format(trading_signal.get('bb_lower'))}
- RS (Amibroker): {rs_val} (SMA10: {rs_sma10_val})
- RS_Point: {rs_point_val:.2f} (SMA10: {rs_point_sma10_val})
- Ichimoku: T:{tenkan_val} | K:{kijun_val} | A:{senkou_a_val} | B:{senkou_b_val} | C:{chikou_val}
2. T√≠n hi·ªáu: {trading_signal['signal']} ({trading_signal['score']:.1f}/100)
"""
        if financial_data is not None and not financial_data.empty:
            prompt += f"\n3. T√†i ch√≠nh (12 qu√Ω g·∫ßn nh·∫•t):\n{financial_data.to_string(index=False)}"
        else:
            prompt += "\n3. Kh√¥ng c√≥ d·ªØ li·ªáu t√†i ch√≠nh."
        prompt += """
Y√™u c·∫ßu:
- Ph√¢n t√≠ch ng·∫Øn g·ªçn, chuy√™n nghi·ªáp (d∆∞·ªõi 300 t·ª´).
- K·∫øt lu·∫≠n r√µ r√†ng: MUA M·∫†NH/MUA/GI·ªÆ/B√ÅN/B√ÅN M·∫†NH.
- L√Ω do d·ª±a tr√™n ƒëi·ªÉm s·ªë v√† ch·ªâ b√°o k·ªπ thu·∫≠t ch√≠nh.
"""
        # --- H·∫æT C·∫¢I TI·∫æN LOGIC T·∫†O PROMPT ---
        model = genai.GenerativeModel("gemini-2.5-flash")
        response = model.generate_content(prompt)
        if response and response.text:
            return response.text.strip()
        else:
            return "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi t·ª´ Google."
    except Exception as e:
        import traceback
        print(f"L·ªói khi ph√¢n t√≠ch b·∫±ng Qwen: {str(e)}")
        print("Chi ti·∫øt l·ªói:")
        traceback.print_exc()
        return "Kh√¥ng th·ªÉ t·∫°o ph√¢n t√≠ch b·∫±ng Google t·∫°i th·ªùi ƒëi·ªÉm n√†y."
# ======================
# PH·∫¶N 6: CH·ª®C NƒÇNG CH√çNH - C·∫¢I TI·∫æN
# ======================
# --- H√†m v·∫Ω bi·ªÉu ƒë·ªì Actual vs Forecast ---
def plot_actual_vs_forecast(symbol, df, forecast_dates, forecast_values):
    """V·∫Ω bi·ªÉu ƒë·ªì so s√°nh gi√° th·ª±c t·∫ø v√† gi√° d·ª± b√°o."""
    try:
        if len(forecast_dates) == 0 or len(forecast_values) == 0:
            print(f"Kh√¥ng c√≥ d·ªØ li·ªáu d·ª± b√°o ƒë·ªÉ v·∫Ω cho {symbol}")
            return
        lookback_days = min(120, len(df))
        actual_data = df['Close'].tail(lookback_days)
        actual_dates = actual_data.index
        plt.figure(figsize=(12, 6))
        plt.plot(actual_dates, actual_data, label='Gi√° th·ª±c t·∫ø (Close)', color='blue', marker='o', markersize=3)
        all_dates = list(actual_dates) + list(forecast_dates)
        connection_x = [actual_dates[-1], forecast_dates[0]]
        connection_y = [actual_data.iloc[-1], forecast_values[0]]
        plt.plot(connection_x, connection_y, color='orange', linestyle='--', alpha=0.7)
        plt.plot(forecast_dates, forecast_values, label=f'Gi√° d·ª± b√°o (AI - {GLOBAL_PREDICTION_DAYS} ng√†y)', color='red', marker='x', markersize=5)
        plt.title(f'Gi√° th·ª±c t·∫ø v√† d·ª± b√°o cho {symbol}')
        plt.xlabel('Ng√†y')
        plt.ylabel('Gi√° (VND)')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        plt.tight_layout()
        filename = f"vnstocks_data/{symbol}_actual_vs_forecast.png"
        plt.savefig(filename)
        plt.close()
        print(f"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì Actual vs Forecast v√†o {filename}")
    except Exception as e:
        print(f"L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì Actual vs Forecast cho {symbol}: {e}")

# --- C·∫¨P NH·∫¨T: Logic l·ª±a ch·ªçn m√¥ h√¨nh trong analyze_stock ---
def analyze_stock(symbol):
    """Ph√¢n t√≠ch to√†n di·ªán m·ªôt m√£ ch·ª©ng kho√°n v·ªõi t√≠ch h·ª£p Google v√† l·ª±a ch·ªçn m√¥ h√¨nh AI ph√π h·ª£p (LSTM ho·∫∑c N-BEATS)"""
    print(f"\n{'='*50}")
    print(f"PH√ÇN T√çCH M√É {symbol} V·ªöI AI")
    print(f"{'='*50}")
    df = get_stock_data(symbol)
    if df is None or df.empty:
        print(f"Kh√¥ng th·ªÉ ph√¢n t√≠ch m√£ {symbol} do thi·∫øu d·ªØ li·ªáu")
        return None
    financial_data = get_financial_data(symbol)
    df_processed = preprocess_stock_data(df)
    if df_processed is None or df_processed.empty:
        print(f"Kh√¥ng th·ªÉ ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu cho m√£ {symbol}")
        return None
    df_features = create_features(df_processed)
    if len(df_features) < 100:
        print(f"D·ªØ li·ªáu cho m√£ {symbol} qu√° √≠t ƒë·ªÉ ph√¢n t√≠ch ({len(df_features)} ƒëi·ªÉm)")
        return None
    
    # --- C·∫¨P NH·∫¨T: Logic l·ª±a ch·ªçn m√¥ h√¨nh ---
    ai_recommendation, ai_reason = evaluate_data_for_ai(df_features, symbol) # Gi·ªØ l·∫°i ƒë·ªÉ so s√°nh chung
    ai_recommendation_nbeats, ai_reason_nbeats = evaluate_data_for_ai_nbeats(df_features, symbol) # Th√™m ƒë√°nh gi√° cho N-BEATS

    # Ch·ªçn m√¥ h√¨nh d·ª±a tr√™n ti√™u ch√≠ ƒë∆°n gi·∫£n (c√≥ th·ªÉ tinh ch·ªânh)
    use_nbeats = ai_recommendation_nbeats == "N-BEATS"

    model, scaler = None, None
    X_test_or_actual, y_test_or_pred, forecast_source = None, None, None
    forecast_dates, forecast_values = np.array([]), np.array([])

    if len(df_features) < 100:
        print(f"C·∫£nh b√°o: D·ªØ li·ªáu cho m√£ {symbol} qu√° √≠t ({len(df_features)} ƒëi·ªÉm) ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh AI hi·ªáu qu·∫£.")
    else:
        if use_nbeats:
            print(f"\nüîî ƒê·ªÄ XU·∫§T M·ªû R·ªòNG: {ai_recommendation_nbeats}")
            print(f"   L√Ω do: {ai_reason_nbeats}")
            print(f"\nƒêang hu·∫•n luy·ªán m√¥ h√¨nh AI (N-BEATS) cho m√£ {symbol}...")
            model, scaler, X_test, y_test_full, y_pred_full = train_stock_model_nbeats(df_features) # G·ªçi tr·ª±c ti·∫øp
            if model is not None:
                 # L·∫•y gi√° tr·ªã cu·ªëi c√πng ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì so s√°nh (ho·∫∑c c√≥ th·ªÉ l·∫•y to√†n b·ªô)
                 X_test_or_actual = y_test_full[:, -1] if y_test_full.ndim > 1 else y_test_full # Gi√° tr·ªã th·ª±c t·∫ø ng√†y cu·ªëi
                 y_test_or_pred = y_pred_full[:, -1] if y_pred_full.ndim > 1 else y_pred_full # D·ª± b√°o ng√†y cu·ªëi
                 print(f"\nƒêang d·ª± b√°o gi√° cho {GLOBAL_PREDICTION_DAYS} ng√†y t·ªõi b·∫±ng N-BEATS...")
                 forecast_dates, forecast_values = predict_next_days_nbeats(model, scaler, df_features) # G·ªçi tr·ª±c ti·∫øp
                 if len(forecast_dates) > 0 and len(forecast_values) > 0:
                      plot_actual_vs_forecast(symbol, df_features, forecast_dates, forecast_values)
            else:
                 print("\n‚ö†Ô∏è Kh√¥ng th·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh N-BEATS.")

        else: # M·∫∑c ƒë·ªãnh s·ª≠ d·ª•ng LSTM
            print(f"\nüîî ƒê·ªÄ XU·∫§T M·ªû R·ªòNG: {ai_recommendation}")
            print(f"   L√Ω do: {ai_reason}")
            print(f"\nƒêang hu·∫•n luy·ªán m√¥ h√¨nh AI (LSTM PyTorch t·ªëi ∆∞u) cho m√£ {symbol}...")
            model, scaler, X_test, y_test, y_pred = train_stock_model_pytorch_optimized(df_features)
            if model is not None:
                X_test_or_actual = y_test
                y_test_or_pred = y_pred
                print(f"\nƒêang d·ª± b√°o gi√° cho {GLOBAL_PREDICTION_DAYS} ng√†y t·ªõi b·∫±ng LSTM PyTorch t·ªëi ∆∞u...")
                forecast_dates, forecast_values = predict_next_days_pytorch_optimized(model, scaler, df_features)
                if len(forecast_dates) > 0 and len(forecast_values) > 0:
                     plot_actual_vs_forecast(symbol, df_features, forecast_dates, forecast_values)
            else:
                print("\n‚ö†Ô∏è Kh√¥ng th·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh LSTM PyTorch t·ªëi ∆∞u.")
    # ... (ph·∫ßn code sau ƒë√≥ trong analyze_stock kh√¥ng thay ƒë·ªïi) ...
    print(f"\nƒêang ph√¢n t√≠ch k·ªπ thu·∫≠t cho m√£ {symbol}...")
    trading_signal = plot_stock_analysis(symbol, df_features)
    print(f"\nƒêang ph√¢n t√≠ch b·∫±ng Google ...")
    gemini_analysis = analyze_with_gemini(symbol, trading_signal, (forecast_dates, forecast_values), financial_data)
    print(f"\nK·∫æT QU·∫¢ PH√ÇN T√çCH CHO M√É {symbol}:")
    print(f"Gi√° hi·ªán t·∫°i: {trading_signal['current_price']:,.2f} VND")
    print(f"T√≠n hi·ªáu: {trading_signal['signal']}")
    print(f"ƒê·ªÅ xu·∫•t: {trading_signal['recommendation']}")
    print(f"ƒêi·ªÉm ph√¢n t√≠ch: {trading_signal['score']:.2f}/100")
    if len(forecast_dates) > 0 and len(forecast_values) > 0:
        print(f"\nD·ª∞ B√ÅO GI√Å CHO {len(forecast_dates)} NG√ÄY TI·∫æP THEO:")
        for i, (date, price) in enumerate(zip(forecast_dates, forecast_values)):
            change = ((price - trading_signal["current_price"])/ trading_signal["current_price"]) * 100
            print(f"Ng√†y {i+1} ({date.date()}): {price:,.2f} VND ({change:+.2f}%)")
    else:
        print("\nKh√¥ng c√≥ d·ª± b√°o gi√° do l·ªói trong qu√° tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh")
    print(f"\nPH√ÇN T√çCH T·ªîNG H·ª¢P T·ª™ Google:")
    print(gemini_analysis)
    def safe_float(val):
        """Chuy·ªÉn ƒë·ªïi gi√° tr·ªã sang float, x·ª≠ l√Ω NaN/None."""
        try:
            if val is None or (isinstance(val, float) and (np.isnan(val) or np.isinf(val))): return None
            return float(val)
        except (TypeError, ValueError): return None
    report = {
        "symbol": symbol, "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "current_price": safe_float(trading_signal.get("current_price")), "signal": trading_signal.get("signal"),
        "recommendation": trading_signal.get("recommendation"), "score": safe_float(trading_signal.get("score")),
        "rsi_value": safe_float(trading_signal.get("rsi_value")), "ma10": safe_float(trading_signal.get("ma10")),
        "ma20": safe_float(trading_signal.get("ma20")), "ma50": safe_float(trading_signal.get("ma50")),
        "ma200": safe_float(trading_signal.get("ma200")), "rs": safe_float(trading_signal.get("rs")),
        "rs_point": safe_float(trading_signal.get("rs_point")),
        "forecast": (
            [{"date": date.strftime("%Y-%m-%d"), "price": safe_float(price), "change_percent": safe_float(change)}
             for date, price, change in zip(forecast_dates, forecast_values,
                [((price - (trading_signal.get("current_price") or 0)) / (trading_signal.get("current_price") or 1)) * 100 for price in forecast_values])]
            if len(forecast_dates) > 0 and len(forecast_values) > 0 and trading_signal.get("current_price") is not None and trading_signal.get("current_price") != 0 else []
        ),
        "ai_recommendation": ai_recommendation, "ai_reason": ai_reason, "gemini_analysis": gemini_analysis,
    }
    report.update(trading_signal)
    with open(f"vnstocks_data/{symbol}_report.json", "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=4)
    print(f"‚úÖ ƒê√£ l∆∞u b√°o c√°o ph√¢n t√≠ch v√†o file 'vnstocks_data/{symbol}_report.json'")
    return report

def screen_stocks_parallel():
    """Qu√©t v√† ph√¢n t√≠ch nhi·ªÅu m√£ ch·ª©ng kho√°n tu·∫ßn t·ª± (sync)."""
    print(f"\n{'='*50}")
    print("QU√âT V√Ä PH√ÇN T√çCH DANH S√ÅCH M√É CH·ª®NG KHO√ÅN (TU·∫¶N T·ª∞ - SYNC)")
    print(f"{'='*50}")
    stock_list = get_vnstocks_list()
    symbols_to_analyze = stock_list["symbol"].head(20)
    results = []
    for symbol in symbols_to_analyze: # Thay v√¨ ch·∫°y song song, ch·∫°y tu·∫ßn t·ª±
        try:
            result = analyze_stock(symbol)
            if result and result["signal"] != "L·ªñI":
                results.append(result)
                print(f"‚úÖ Ph√¢n t√≠ch m√£ {symbol} ho√†n t·∫•t (tu·∫ßn t·ª± - sync).")
            else:
                print(f"‚ö†Ô∏è Ph√¢n t√≠ch m√£ {symbol} th·∫•t b·∫°i ho·∫∑c c√≥ l·ªói (tu·∫ßn t·ª± - sync).")
        except Exception as e:
            print(f"L·ªói khi ph√¢n t√≠ch m√£ {symbol} (tu·∫ßn t·ª± - sync): {e}")
            import traceback
            traceback.print_exc()

    if results:
        results.sort(key=lambda x: x["score"], reverse=True)
        def get_nested_value(report_dict, key_path, default=None):
            keys = key_path.split(".")
            current_dict = report_dict
            try:
                for key in keys:
                    if isinstance(current_dict, dict) and key in current_dict: current_dict = current_dict[key]
                    else: return default
                if current_dict is None or (isinstance(current_dict, float) and (pd.isna(current_dict) or np.isinf(current_dict))): return default
                return float(current_dict)
            except (ValueError, TypeError): return default
        data_for_df = []
        for r in results:
            row_data = {
                "M√£": r["symbol"], "Gi√°": r["current_price"], "ƒêi·ªÉm": r["score"], "T√≠n hi·ªáu": r["signal"], "ƒê·ªÅ xu·∫•t": r["recommendation"],
                "RSI": r["rsi_value"], "MA10": r["ma10"], "MA20": r["ma20"], "MA50": r["ma50"], "MA200": r["ma200"],
                "RS": r["rs"], "RS_Point": r["rs_point"],
                "Ichimoku_Tenkan": r.get("ichimoku_tenkan_sen"), "Ichimoku_Kijun": r.get("ichimoku_kijun_sen"),
                "Ichimoku_Senkou_A": r.get("ichimoku_senkou_span_a"), "Ichimoku_Senkou_B": r.get("ichimoku_senkou_span_b"),
                "Ichimoku_Chikou": r.get("ichimoku_chikou_span"),
            }
            data_for_df.append(row_data)
        df_results = pd.DataFrame(data_for_df)
        df_results.to_csv("vnstocks_data/stock_screening_report.csv", index=False)
        print(f"\n{'='*50}")
        print("K·∫æT QU·∫¢ QU√âT M√É")
        print(f"{'='*50}")
        print_cols = ["M√£", "Gi√°", "ƒêi·ªÉm", "T√≠n hi·ªáu", "ƒê·ªÅ xu·∫•t"]
        print(df_results[print_cols])
        try:
            plt.figure(figsize=(14, 6))
            sns.barplot(x="M√£", y="ƒêi·ªÉm", data=df_results.head(20), palette="viridis")
            plt.title("Top ƒêi·ªÉm ph√¢n t√≠ch c√°c m√£ ch·ª©ng kho√°n")
            plt.xticks(rotation=45)
            plt.tight_layout()
            plt.savefig("vnstocks_data/stock_screening_comparison.png")
            plt.close()
        except Exception as e:
            print(f"L·ªói khi v·∫Ω bi·ªÉu ƒë·ªì so s√°nh: {str(e)}")
        print(f"\nƒê√£ l∆∞u b√°o c√°o t·ªïng h·ª£p v√†o file 'vnstocks_data/stock_screening_report.csv'")
        print("ƒê√£ t·∫°o bi·ªÉu ƒë·ªì so s√°nh c√°c m√£")
        return df_results
    else:
        print("\nKh√¥ng c√≥ k·∫øt qu·∫£ ph√¢n t√≠ch n√†o ƒë·ªÉ t·∫°o b√°o c√°o t·ªïng h·ª£p.")
    return None
# ======================
# CH·∫†Y CH∆Ø∆†NG TR√åNH CH√çNH
# ======================
def main():
    print("==============================================")
    print("H·ªÜ TH·ªêNG PH√ÇN T√çCH CH·ª®NG KHO√ÅN VI·ªÜT NAM V·ªöI AI")
    print("T√çCH H·ª¢P VNSTOCK V√Ä GOOGLE - PHI√äN B·∫¢N T·ªêI ∆ØU")
    print("==============================================")
    market_data = get_market_data()
    analyze_stock("DRI") # C√≥ th·ªÉ thay b·∫±ng m√£ kh√°c ho·∫∑c b·ªè comment d√≤ng d∆∞·ªõi ƒë·ªÉ qu√©t danh s√°ch
    # screen_stocks_parallel() # G·ªçi tr·ª±c ti·∫øp, kh√¥ng d√πng await
    print("\nHo√†n th√†nh ph√¢n t√≠ch. C√°c b√°o c√°o ƒë√£ ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c 'vnstocks_data/'.")
if __name__ == "__main__":
    main() # G·ªçi tr·ª±c ti·∫øp, kh√¥ng d√πng asyncio.run()
# --- K·∫æT TH√öC: TO√ÄN B·ªò M√É NGU·ªíN ƒê√É C·∫¨P NH·∫¨T & T·ªêI ∆ØU TO√ÄN DI·ªÜN ---
